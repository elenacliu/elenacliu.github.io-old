[{"id":0,"href":"/post/2023-07-08-Maven_%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0/","title":"Maven 使用小记","section":"Posts","content":" Maven 使用小记 # 本文主要内容整理自菜鸟教程：https://www.runoob.com/maven/maven-tutorial.html，此处作为备忘录进行记录。感谢前人的知识总结和分享！\nMaven 官方 tutorial：https://maven.apache.org/guides/getting-started/index.html\n什么是 Maven # Maven 是 Apache 下的一个项目管理工具，可以对 Java 项目进行构建和依赖管理。同时，Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。\nMaven 约定配置 # Maven 提倡使用一个共同的标准目录结构，Maven 使用约定优于配置的原则，要尽可能遵守这样的目录结构：\n目录 目的 ${basedir} 存放pom.xml和所有的子目录 ${basedir}/src/main/java 项目的java源代码 ${basedir}/src/main/resources 项目的资源，比如说property文件，springmvc.xml ${basedir}/src/test/java 项目的测试类，比如说Junit代码 ${basedir}/src/test/resources 测试用的资源 ${basedir}/src/main/webapp/WEB-INF web应用文件目录，web项目的信息，比如存放web.xml、本地图片、jsp视图页面 ${basedir}/target 打包输出目录 ${basedir}/target/classes 编译输出目录 ${basedir}/target/test-classes 测试编译输出目录 Test.java Maven只会自动运行符合该命名规则的测试类 ~/.m2/repository Maven默认的本地仓库目录位置；mvn install 时会将打包文件部署到本地 Maven 仓库，如果没有设置仓库路径，就在这个路径下 Maven POM # POM（project object model）是 Maven 的基本工作单元，命名为 pom.xml，包含了项目的基本信息，用于描述项目如何构建、声明项目依赖等。\n在创建 POM 之前，我们首先需要描述项目组 (groupId), 项目的唯一ID。\n\u0026lt;project xmlns = \u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi = \u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation = \u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;!-- 模型版本 --\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;!-- 公司或者组织的唯一标志，并且配置时生成的路径也是由此生成， 如com.companyname.project-group，maven会将该项目打成的jar包放本地路径：/com/companyname/project-group --\u0026gt; \u0026lt;groupId\u0026gt;com.companyname.project-group\u0026lt;/groupId\u0026gt; \u0026lt;!-- 项目的唯一ID，一个groupId下面可能多个项目，就是靠artifactId来区分的 --\u0026gt; \u0026lt;artifactId\u0026gt;project\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 版本号 --\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;/project\u0026gt; 所有 POM 文件都需要 project 元素和三个必需字段：groupId，artifactId，version。\n节点 描述 project 工程的根标签。 modelVersion 模型版本需要设置为 4.0。 groupId 这是工程组的标识。它在一个组织或者项目中通常是唯一的。例如，一个银行组织 com.company.bank 拥有所有的和银行相关的项目。 artifactId 这是工程的标识。它通常是工程的名称。例如：consumer-banking。groupId 和 artifactId 一起定义了 artifact 在仓库中的位置。 version 这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。例如：com.company.bank:consumer-banking:1.0 com.company.bank:consumer-banking:1.1 父（Super）POM是 Maven 默认的 POM。所有的 POM 都继承自一个父 POM（无论是否显式定义了这个父 POM）。父 POM 包含了一些可以被继承的默认设置。因此，当 Maven 发现需要下载 POM 中的 依赖时，它会到 Super POM 中配置的默认仓库 http://repo1.maven.org/maven2 去下载。\nMaven 使用 effective pom（Super pom 加上工程自己的配置）来执行相关的目标，它帮助开发者在 pom.xml 中做尽可能少的配置，当然这些配置可以被重写。\n使用以下命令来查看 Super POM 默认配置：\nmvn help:effective-pom Maven 的 pom.xml 文件也不需要手工编写。\nMaven 提供了大量的原型插件来创建工程，包括工程结构和 pom.xml。\nPOM 标签大全 # \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;!--被继承的父项目的构件标识符 --\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;!--被继承的父项目的全球唯一标识符 --\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;!--被继承的父项目的版本 --\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --\u0026gt; \u0026lt;relativePath /\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --\u0026gt; \u0026lt;groupId\u0026gt;asia.banseon\u0026lt;/groupId\u0026gt; \u0026lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。 --\u0026gt; \u0026lt;artifactId\u0026gt;banseon-maven2\u0026lt;/artifactId\u0026gt; \u0026lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;!--项目的名称, Maven产生的文档用 --\u0026gt; \u0026lt;name\u0026gt;banseon-maven\u0026lt;/name\u0026gt; \u0026lt;!--项目主页的URL, Maven产生的文档用 --\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --\u0026gt; \u0026lt;description\u0026gt;A maven project to study maven.\u0026lt;/description\u0026gt; \u0026lt;!--描述了这个项目构建环境中的前提条件。 --\u0026gt; \u0026lt;prerequisites\u0026gt; \u0026lt;!--构建该项目或使用该插件所需要的Maven的最低版本 --\u0026gt; \u0026lt;maven /\u0026gt; \u0026lt;/prerequisites\u0026gt; \u0026lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --\u0026gt; \u0026lt;issueManagement\u0026gt; \u0026lt;!--问题管理系统（例如jira）的名字， --\u0026gt; \u0026lt;system\u0026gt;jira\u0026lt;/system\u0026gt; \u0026lt;!--该项目使用的问题管理系统的URL --\u0026gt; \u0026lt;url\u0026gt;http://jira.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/issueManagement\u0026gt; \u0026lt;!--项目持续集成信息 --\u0026gt; \u0026lt;ciManagement\u0026gt; \u0026lt;!--持续集成系统的名字，例如continuum --\u0026gt; \u0026lt;system /\u0026gt; \u0026lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --\u0026gt; \u0026lt;url /\u0026gt; \u0026lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --\u0026gt; \u0026lt;notifiers\u0026gt; \u0026lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者 --\u0026gt; \u0026lt;notifier\u0026gt; \u0026lt;!--传送通知的途径 --\u0026gt; \u0026lt;type /\u0026gt; \u0026lt;!--发生错误时是否通知 --\u0026gt; \u0026lt;sendOnError /\u0026gt; \u0026lt;!--构建失败时是否通知 --\u0026gt; \u0026lt;sendOnFailure /\u0026gt; \u0026lt;!--构建成功时是否通知 --\u0026gt; \u0026lt;sendOnSuccess /\u0026gt; \u0026lt;!--发生警告时是否通知 --\u0026gt; \u0026lt;sendOnWarning /\u0026gt; \u0026lt;!--不赞成使用。通知发送到哪里 --\u0026gt; \u0026lt;address /\u0026gt; \u0026lt;!--扩展配置项 --\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/notifier\u0026gt; \u0026lt;/notifiers\u0026gt; \u0026lt;/ciManagement\u0026gt; \u0026lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --\u0026gt; \u0026lt;inceptionYear /\u0026gt; \u0026lt;!--项目相关邮件列表信息 --\u0026gt; \u0026lt;mailingLists\u0026gt; \u0026lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --\u0026gt; \u0026lt;mailingList\u0026gt; \u0026lt;!--邮件的名称 --\u0026gt; \u0026lt;name\u0026gt;Demo\u0026lt;/name\u0026gt; \u0026lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --\u0026gt; \u0026lt;post\u0026gt;banseon@126.com\u0026lt;/post\u0026gt; \u0026lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --\u0026gt; \u0026lt;subscribe\u0026gt;banseon@126.com\u0026lt;/subscribe\u0026gt; \u0026lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --\u0026gt; \u0026lt;unsubscribe\u0026gt;banseon@126.com\u0026lt;/unsubscribe\u0026gt; \u0026lt;!--你可以浏览邮件信息的URL --\u0026gt; \u0026lt;archive\u0026gt;http:/hi.baidu.com/banseon/demo/dev/\u0026lt;/archive\u0026gt; \u0026lt;/mailingList\u0026gt; \u0026lt;/mailingLists\u0026gt; \u0026lt;!--项目开发者列表 --\u0026gt; \u0026lt;developers\u0026gt; \u0026lt;!--某个项目开发者的信息 --\u0026gt; \u0026lt;developer\u0026gt; \u0026lt;!--SCM里项目开发者的唯一标识符 --\u0026gt; \u0026lt;id\u0026gt;HELLO WORLD\u0026lt;/id\u0026gt; \u0026lt;!--项目开发者的全名 --\u0026gt; \u0026lt;name\u0026gt;banseon\u0026lt;/name\u0026gt; \u0026lt;!--项目开发者的email --\u0026gt; \u0026lt;email\u0026gt;banseon@126.com\u0026lt;/email\u0026gt; \u0026lt;!--项目开发者的主页的URL --\u0026gt; \u0026lt;url /\u0026gt; \u0026lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色 --\u0026gt; \u0026lt;roles\u0026gt; \u0026lt;role\u0026gt;Project Manager\u0026lt;/role\u0026gt; \u0026lt;role\u0026gt;Architect\u0026lt;/role\u0026gt; \u0026lt;/roles\u0026gt; \u0026lt;!--项目开发者所属组织 --\u0026gt; \u0026lt;organization\u0026gt;demo\u0026lt;/organization\u0026gt; \u0026lt;!--项目开发者所属组织的URL --\u0026gt; \u0026lt;organizationUrl\u0026gt;http://hi.baidu.com/banseon\u0026lt;/organizationUrl\u0026gt; \u0026lt;!--项目开发者属性，如即时消息如何处理等 --\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;dept\u0026gt;No\u0026lt;/dept\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;!--项目开发者所在时区， -11到12范围内的整数。 --\u0026gt; \u0026lt;timezone\u0026gt;-5\u0026lt;/timezone\u0026gt; \u0026lt;/developer\u0026gt; \u0026lt;/developers\u0026gt; \u0026lt;!--项目的其他贡献者列表 --\u0026gt; \u0026lt;contributors\u0026gt; \u0026lt;!--项目的其他贡献者。参见developers/developer元素 --\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name /\u0026gt; \u0026lt;email /\u0026gt; \u0026lt;url /\u0026gt; \u0026lt;organization /\u0026gt; \u0026lt;organizationUrl /\u0026gt; \u0026lt;roles /\u0026gt; \u0026lt;timezone /\u0026gt; \u0026lt;properties /\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;/contributors\u0026gt; \u0026lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --\u0026gt; \u0026lt;licenses\u0026gt; \u0026lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --\u0026gt; \u0026lt;license\u0026gt; \u0026lt;!--license用于法律上的名称 --\u0026gt; \u0026lt;name\u0026gt;Apache 2\u0026lt;/name\u0026gt; \u0026lt;!--官方的license正文页面的URL --\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon/LICENSE-2.0.txt\u0026lt;/url\u0026gt; \u0026lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --\u0026gt; \u0026lt;distribution\u0026gt;repo\u0026lt;/distribution\u0026gt; \u0026lt;!--关于license的补充信息 --\u0026gt; \u0026lt;comments\u0026gt;A business-friendly OSS license\u0026lt;/comments\u0026gt; \u0026lt;/license\u0026gt; \u0026lt;/licenses\u0026gt; \u0026lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --\u0026gt; \u0026lt;scm\u0026gt; \u0026lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --\u0026gt; \u0026lt;connection\u0026gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) \u0026lt;/connection\u0026gt; \u0026lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读 --\u0026gt; \u0026lt;developerConnection\u0026gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk \u0026lt;/developerConnection\u0026gt; \u0026lt;!--当前代码的标签，在开发阶段默认为HEAD --\u0026gt; \u0026lt;tag /\u0026gt; \u0026lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --\u0026gt; \u0026lt;url\u0026gt;http://svn.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/scm\u0026gt; \u0026lt;!--描述项目所属组织的各种属性。Maven产生的文档用 --\u0026gt; \u0026lt;organization\u0026gt; \u0026lt;!--组织的全名 --\u0026gt; \u0026lt;name\u0026gt;demo\u0026lt;/name\u0026gt; \u0026lt;!--组织主页的URL --\u0026gt; \u0026lt;url\u0026gt;http://www.baidu.com/banseon\u0026lt;/url\u0026gt; \u0026lt;/organization\u0026gt; \u0026lt;!--构建项目需要的信息 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --\u0026gt; \u0026lt;sourceDirectory /\u0026gt; \u0026lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --\u0026gt; \u0026lt;scriptSourceDirectory /\u0026gt; \u0026lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --\u0026gt; \u0026lt;testSourceDirectory /\u0026gt; \u0026lt;!--被编译过的应用程序class文件存放的目录。 --\u0026gt; \u0026lt;outputDirectory /\u0026gt; \u0026lt;!--被编译过的测试class文件存放的目录。 --\u0026gt; \u0026lt;testOutputDirectory /\u0026gt; \u0026lt;!--使用来自该项目的一系列构建扩展 --\u0026gt; \u0026lt;extensions\u0026gt; \u0026lt;!--描述使用到的构建扩展。 --\u0026gt; \u0026lt;extension\u0026gt; \u0026lt;!--构建扩展的groupId --\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;!--构建扩展的artifactId --\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;!--构建扩展的版本 --\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/extensions\u0026gt; \u0026lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值 --\u0026gt; \u0026lt;defaultGoal /\u0026gt; \u0026lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;!--这个元素描述了项目相关或测试相关的所有资源路径 --\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如${project.build.outputDirectory}）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --\u0026gt; \u0026lt;targetPath /\u0026gt; \u0026lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --\u0026gt; \u0026lt;filtering /\u0026gt; \u0026lt;!--描述存放资源的目录，该路径相对POM路径 --\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;!--包含的模式列表，例如**/*.xml. --\u0026gt; \u0026lt;includes /\u0026gt; \u0026lt;!--排除的模式列表，例如**/*.xml --\u0026gt; \u0026lt;excludes /\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --\u0026gt; \u0026lt;testResources\u0026gt; \u0026lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --\u0026gt; \u0026lt;testResource\u0026gt; \u0026lt;targetPath /\u0026gt; \u0026lt;filtering /\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;includes /\u0026gt; \u0026lt;excludes /\u0026gt; \u0026lt;/testResource\u0026gt; \u0026lt;/testResources\u0026gt; \u0026lt;!--构建产生的所有文件存放的目录 --\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;!--产生的构件的文件名，默认值是artifactId− {version}。 --\u0026gt; \u0026lt;finalName /\u0026gt; \u0026lt;!--当filtering开关打开时，使用到的过滤器属性文件列表 --\u0026gt; \u0026lt;filters /\u0026gt; \u0026lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;!--使用的插件列表 。 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--plugin元素包含描述插件所需要的信息。 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!--插件在仓库里的group ID --\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;!--插件在仓库里的artifact ID --\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;!--被使用的插件的版本（或版本范围） --\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --\u0026gt; \u0026lt;extensions /\u0026gt; \u0026lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;!--execution元素包含了插件执行需要的信息 --\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --\u0026gt; \u0026lt;phase /\u0026gt; \u0026lt;!--配置的执行目标 --\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;!--配置是否被传播到子POM --\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;!--作为DOM对象的配置 --\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;!--项目引入插件所需要的额外依赖 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--任何配置是否被传播到子项目 --\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;!--作为DOM对象的配置 --\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;!--使用的插件列表 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;extensions /\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;phase /\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--在列的项目构建profile，如果被激活，会修改构建处理 --\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;!--根据环境参数或命令行参数激活某个构建处理 --\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;!--profile默认是否激活的标志 --\u0026gt; \u0026lt;activeByDefault /\u0026gt; \u0026lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --\u0026gt; \u0026lt;jdk /\u0026gt; \u0026lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --\u0026gt; \u0026lt;os\u0026gt; \u0026lt;!--激活profile的操作系统的名字 --\u0026gt; \u0026lt;name\u0026gt;Windows XP\u0026lt;/name\u0026gt; \u0026lt;!--激活profile的操作系统所属家族(如 \u0026#39;windows\u0026#39;) --\u0026gt; \u0026lt;family\u0026gt;Windows\u0026lt;/family\u0026gt; \u0026lt;!--激活profile的操作系统体系结构 --\u0026gt; \u0026lt;arch\u0026gt;x86\u0026lt;/arch\u0026gt; \u0026lt;!--激活profile的操作系统版本 --\u0026gt; \u0026lt;version\u0026gt;5.1.2600\u0026lt;/version\u0026gt; \u0026lt;/os\u0026gt; \u0026lt;!--如果Maven检测到某一个属性（其值可以在POM中通过${名称}引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;!--激活profile的属性的名称 --\u0026gt; \u0026lt;name\u0026gt;mavenVersion\u0026lt;/name\u0026gt; \u0026lt;!--激活profile的属性的值 --\u0026gt; \u0026lt;value\u0026gt;2.0.3\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --\u0026gt; \u0026lt;file\u0026gt; \u0026lt;!--如果指定的文件存在，则激活profile。 --\u0026gt; \u0026lt;exists\u0026gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ \u0026lt;/exists\u0026gt; \u0026lt;!--如果指定的文件不存在，则激活profile。 --\u0026gt; \u0026lt;missing\u0026gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ \u0026lt;/missing\u0026gt; \u0026lt;/file\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;!--构建项目所需要的信息。参见build元素 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;defaultGoal /\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;targetPath /\u0026gt; \u0026lt;filtering /\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;includes /\u0026gt; \u0026lt;excludes /\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;testResources\u0026gt; \u0026lt;testResource\u0026gt; \u0026lt;targetPath /\u0026gt; \u0026lt;filtering /\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;includes /\u0026gt; \u0026lt;excludes /\u0026gt; \u0026lt;/testResource\u0026gt; \u0026lt;/testResources\u0026gt; \u0026lt;directory /\u0026gt; \u0026lt;finalName /\u0026gt; \u0026lt;filters /\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;extensions /\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;phase /\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--参见build/pluginManagement/plugins/plugin元素 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;extensions /\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;phase /\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;goals /\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --\u0026gt; \u0026lt;modules /\u0026gt; \u0026lt;!--发现依赖和扩展的远程仓库列表。 --\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;!--参见repositories/repository元素 --\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;name /\u0026gt; \u0026lt;url /\u0026gt; \u0026lt;layout /\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;name /\u0026gt; \u0026lt;url /\u0026gt; \u0026lt;layout /\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--不赞成使用. 现在Maven忽略该元素. --\u0026gt; \u0026lt;reports /\u0026gt; \u0026lt;!--该元素包括使用报表插件产生报表的规范。当用户执行\u0026#34;mvn site\u0026#34;，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --\u0026gt; \u0026lt;reporting\u0026gt; ...... \u0026lt;/reporting\u0026gt; \u0026lt;!--参见dependencyManagement元素 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--参见distributionManagement元素 --\u0026gt; \u0026lt;distributionManagement\u0026gt; ...... \u0026lt;/distributionManagement\u0026gt; \u0026lt;!--参见properties元素 --\u0026gt; \u0026lt;properties /\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --\u0026gt; \u0026lt;modules /\u0026gt; \u0026lt;!--发现依赖和扩展的远程仓库列表。 --\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;!--包含需要连接到远程仓库的信息 --\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!--如何处理远程仓库里发布版本的下载 --\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled /\u0026gt; \u0026lt;updatePolicy /\u0026gt; \u0026lt;checksumPolicy /\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --\u0026gt; \u0026lt;id\u0026gt;banseon-repository-proxy\u0026lt;/id\u0026gt; \u0026lt;!--远程仓库名称 --\u0026gt; \u0026lt;name\u0026gt;banseon-repository-proxy\u0026lt;/name\u0026gt; \u0026lt;!--远程仓库URL，按protocol://hostname/path形式 --\u0026gt; \u0026lt;url\u0026gt;http://192.168.1.169:9999/repository/\u0026lt;/url\u0026gt; \u0026lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --\u0026gt; \u0026lt;layout\u0026gt;default\u0026lt;/layout\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --\u0026gt; \u0026lt;pluginRepository\u0026gt; ...... \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;!--依赖的group ID --\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven\u0026lt;/groupId\u0026gt; \u0026lt;!--依赖的artifact ID --\u0026gt; \u0026lt;artifactId\u0026gt;maven-artifact\u0026lt;/artifactId\u0026gt; \u0026lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。 --\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --\u0026gt; \u0026lt;classifier\u0026gt;\u0026lt;/classifier\u0026gt; \u0026lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如${java.home}。 --\u0026gt; \u0026lt;systemPath\u0026gt;\u0026lt;/systemPath\u0026gt; \u0026lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!--不赞成使用. 现在Maven忽略该元素. --\u0026gt; \u0026lt;reports\u0026gt;\u0026lt;/reports\u0026gt; \u0026lt;!--该元素描述使用报表插件产生报表的规范。当用户执行\u0026#34;mvn site\u0026#34;，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --\u0026gt; \u0026lt;reporting\u0026gt; \u0026lt;!--true，则，网站不包括默认的报表。这包括\u0026#34;项目信息\u0026#34;菜单中的报表。 --\u0026gt; \u0026lt;excludeDefaults /\u0026gt; \u0026lt;!--所有产生的报表存放到哪里。默认值是${project.build.directory}/site。 --\u0026gt; \u0026lt;outputDirectory /\u0026gt; \u0026lt;!--使用的报表插件和他们的配置。 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!--plugin元素包含描述报表插件需要的信息 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!--报表插件在仓库里的group ID --\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;!--报表插件在仓库里的artifact ID --\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;!--被使用的报表插件的版本（或版本范围） --\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;!--任何配置是否被传播到子项目 --\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;!--报表插件的配置 --\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --\u0026gt; \u0026lt;reportSets\u0026gt; \u0026lt;!--表示报表的一个集合，以及产生该集合的配置 --\u0026gt; \u0026lt;reportSet\u0026gt; \u0026lt;!--报表集合的唯一标识符，POM继承时用到 --\u0026gt; \u0026lt;id /\u0026gt; \u0026lt;!--产生报表集合时，被使用的报表的配置 --\u0026gt; \u0026lt;configuration /\u0026gt; \u0026lt;!--配置是否被继承到子POMs --\u0026gt; \u0026lt;inherited /\u0026gt; \u0026lt;!--这个集合里使用到哪些报表 --\u0026gt; \u0026lt;reports /\u0026gt; \u0026lt;/reportSet\u0026gt; \u0026lt;/reportSets\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/reporting\u0026gt; \u0026lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--参见dependencies/dependency元素 --\u0026gt; \u0026lt;dependency\u0026gt; ...... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --\u0026gt; \u0026lt;distributionManagement\u0026gt; \u0026lt;!--部署项目产生的构件到远程仓库需要的信息 --\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --\u0026gt; \u0026lt;uniqueVersion /\u0026gt; \u0026lt;id\u0026gt;banseon-maven2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;banseon maven2\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;file://${basedir}/target/deploy\u0026lt;/url\u0026gt; \u0026lt;layout /\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --\u0026gt; \u0026lt;snapshotRepository\u0026gt; \u0026lt;uniqueVersion /\u0026gt; \u0026lt;id\u0026gt;banseon-maven2\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Banseon-maven2 Snapshot Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot\u0026lt;/url\u0026gt; \u0026lt;layout /\u0026gt; \u0026lt;/snapshotRepository\u0026gt; \u0026lt;!--部署项目的网站需要的信息 --\u0026gt; \u0026lt;site\u0026gt; \u0026lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --\u0026gt; \u0026lt;id\u0026gt;banseon-site\u0026lt;/id\u0026gt; \u0026lt;!--部署位置的名称 --\u0026gt; \u0026lt;name\u0026gt;business api website\u0026lt;/name\u0026gt; \u0026lt;!--部署位置的URL，按protocol://hostname/path形式 --\u0026gt; \u0026lt;url\u0026gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web \u0026lt;/url\u0026gt; \u0026lt;/site\u0026gt; \u0026lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --\u0026gt; \u0026lt;downloadUrl /\u0026gt; \u0026lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --\u0026gt; \u0026lt;relocation\u0026gt; \u0026lt;!--构件新的group ID --\u0026gt; \u0026lt;groupId /\u0026gt; \u0026lt;!--构件新的artifact ID --\u0026gt; \u0026lt;artifactId /\u0026gt; \u0026lt;!--构件新的版本号 --\u0026gt; \u0026lt;version /\u0026gt; \u0026lt;!--显示给用户的，关于移动的额外信息，例如原因。 --\u0026gt; \u0026lt;message /\u0026gt; \u0026lt;/relocation\u0026gt; \u0026lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。 --\u0026gt; \u0026lt;status /\u0026gt; \u0026lt;/distributionManagement\u0026gt; \u0026lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是\u0026lt;name\u0026gt;value\u0026lt;/name\u0026gt;。 --\u0026gt; \u0026lt;properties /\u0026gt; \u0026lt;/project\u0026gt; Maven 构建 # Maven 构建生命周期 # Maven 构建生命周期定义了一个项目构建跟发布的过程。\n一个典型的 Maven 构建（build）生命周期是由以下几个阶段的序列组成的：\n验证 validate 验证项目 验证项目是否正确且所有必须信息是可用的 编译 compile 执行编译 源代码编译在此阶段完成 测试 Test 测试 使用适当的单元测试框架（例如JUnit）运行测试。 包装 package 打包 创建JAR/WAR包，如在 pom.xml 中定义提及的包 检查 verify 检查 对集成测试的结果进行检查，以保证质量达标 安装 install 安装 安装打包的项目到本地仓库，以供其他项目使用 部署 deploy 部署 拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程 为了完成 default 生命周期，这些阶段（包括其他未在上面罗列的生命周期阶段）将被按顺序地执行。\nMaven 有以下三个标准的生命周期：\nclean：项目清理的处理 default(或 build)：项目部署的处理 site：项目站点文档创建的处理 每个生命周期中都包含着一系列的阶段(phase)。这些 phase 就相当于 Maven 提供的统一的接口，然后这些 phase 的实现由 Maven 的插件来完成。\n我们在输入 mvn 命令的时候，比如 mvn clean，clean 对应的就是 Clean 生命周期中的 clean 阶段。但是 clean 的具体操作是由 maven-clean-plugin 来实现的。所以说 Maven 生命周期的每一个阶段的具体实现都是由 Maven 插件实现的。\n插件通常提供了一个目标的集合，并且可以使用下面的语法执行：\nmvn [plugin-name]:[goal-name] 例如，一个 Java 工程可以使用 maven-compiler-plugin 的 compile-goal 编译，使用以下命令：\nmvn compiler:compile 在 Maven 中，有两种类型的插件，build 和 reporting：\nBuild plugins are executed during the build and configured in the \u0026lt;build/\u0026gt; element. Reporting plugins are executed during the site generation and configured in the \u0026lt;reporting/\u0026gt; element. 所有的插件都至少需要三个信息: groupId, artifactId and version.\n下面是一些常用插件的列表：\n插件 描述 clean 构建之后清理目标文件。删除目标目录。 compiler 编译 Java 源文件。 surefile 运行 JUnit 单元测试。创建测试报告。 jar 从当前工程中构建 JAR 文件。 war 从当前工程中构建 WAR 文件。 javadoc 为工程生成 Javadoc。 antrun 从构建过程的任意一个阶段中运行一个 ant 任务的集合。 Maven 官方支持的所有插件参见：https://maven.apache.org/plugins/ 和 https://repo.maven.apache.org/maven2/org/apache/maven/plugins/\n除了官方支持的插件外，还有一些第三方的插件库，如我在测试 RocketMQ-Streams 时经常使用的命令：\nmvn exec:java -Dexec.mainClass=\u0026#34;org.apache.rocketmq.streams.examples.WordCount \u0026#34; -pl example 这里的 exec 插件的配置就是：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;exec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; ... \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;exec\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;executable\u0026gt;maven\u0026lt;/executable\u0026gt; \u0026lt;!-- optional --\u0026gt; \u0026lt;workingDirectory\u0026gt;/tmp\u0026lt;/workingDirectory\u0026gt; \u0026lt;arguments\u0026gt; \u0026lt;argument\u0026gt;-X\u0026lt;/argument\u0026gt; \u0026lt;argument\u0026gt;myproject:dist\u0026lt;/argument\u0026gt; ... \u0026lt;/arguments\u0026gt; \u0026lt;environmentVariables\u0026gt; \u0026lt;LANG\u0026gt;en_US\u0026lt;/LANG\u0026gt; \u0026lt;/environmentVariables\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 但最近在开发过程中发现 RocketMQ-Streams 并没有配置这个插件，但却可以使用 mvn exec:java 命令，具体原因还在探索中。\nMaven 依赖搜索顺序 # 当我们执行 Maven 构建命令时，Maven 开始按照以下顺序查找依赖的库：\n步骤 1 － 在本地仓库中搜索，如果找不到，执行步骤 2，如果找到了则执行其他操作。 步骤 2 － 在中央仓库中搜索，如果找不到，并且有一个或多个远程仓库已经设置，则执行步骤 4，如果找到了则下载到本地仓库中以备将来引用。 步骤 3 － 如果远程仓库没有被设置，Maven 将简单的停滞处理并抛出错误（无法找到依赖的文件）。 步骤 4 － 在一个或多个远程仓库中搜索依赖的文件，如果找到则下载到本地仓库以备将来引用，否则 Maven 将停止处理并抛出错误（无法找到依赖的文件）。 Maven 打包命令 # mvn package: 打包到本项目，一般在项目 target 目录下。\nmvn install: 打包到本地仓库，如果没设置 Maven 本地仓库，一般在 $HOME/.m2 目录下。\nmvn deploy: 打包上传到远程仓库，具体设置可以参考：https://maven.apache.org/guides/getting-started/index.html#how-do-i-deploy-my-jar-in-my-remote-repository\nFor deploying jars to an external repository, you have to configure the repository url in the pom.xml and the authentication information for connecting to the repository in the settings.xml.\nMaven SNAPSHOT # What is a SNAPSHOT version? # Notice the value of the version tag in the pom.xml file shown below has the suffix: -SNAPSHOT.\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; ... \u0026lt;groupId\u0026gt;...\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;my-app\u0026lt;/artifactId\u0026gt; ... \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;Maven Quick Start Archetype\u0026lt;/name\u0026gt; ... The SNAPSHOT value refers to the \u0026rsquo;latest\u0026rsquo; code along a development branch, and provides no guarantee the code is stable or unchanging. Conversely, the code in a \u0026lsquo;release\u0026rsquo; version (any version value without the suffix SNAPSHOT) is unchanging.\nIn other words, a SNAPSHOT version is the \u0026lsquo;development\u0026rsquo; version before the final \u0026lsquo;release\u0026rsquo; version. The SNAPSHOT is \u0026ldquo;older\u0026rdquo; than its release.\nDuring the release process, a version of x.y-SNAPSHOT changes to x.y. The release process also increments the development version to x.(y+1)-SNAPSHOT. For example, version 1.0-SNAPSHOT is released as version 1.0, and the new development version is version 1.1-SNAPSHOT.\n因此，如果要使用当前正在开发的代码进行构建，那么版本号应该使用 未来版本号-SNAPSHOT 的格式。\n"},{"id":1,"href":"/post/","title":"Posts","section":"cliu's Blog","content":""},{"id":2,"href":"/post/2023-07-03-6D-Pose-Estimation/","title":"6D Pose Estimation","section":"Posts","content":" 6D Pose Estimation # 6D Pose # 6D pose means the 6 degrees of freedom of an object in camera-centered coordinates: 3D position $\\mathrm{x}=(x,y,z)$ and 3D orientation $\\theta=(r,p,y)$, where $r$ means roll (翻滚角), $p$ means pitch (俯仰角), and $y$ means yaw (偏航角).\nThe three nouns come from aviation. The gifs below from this site illustrate them clearly:\nroll:\npitch:\nyaw:\nThe picture below shows which coordinate axis the three rotation angles correspond to.\nPose Estimation # Instance-level pose estimation # Single instance # Given an RGB-D image input $I$ where an instance $S$ of the interested object $O$ exists, we cast 6D object pose estimation as a joint probability estimation problem, and formulate it as given below: $$ (\\mathrm{x}, \\theta)^*=\\arg\\max_{\\mathrm{x}, \\theta}p(\\mathrm{x},\\theta|I,S) $$ This formulation assumes that there only exists one instance of the interested object in the RGB-D image I, and hence, producing the pair of pose parameters $(\\mathrm{x}, \\theta)$, which is of the instance $S$. Note that, this existence is apriori known by any 6D object pose estimation method. So to an extent, pose estimation includes the object detection task.\nQ: How is the information of instance $S$ given?\nA:\nMulti-instances # In case the image $I$ involves multiple instances $\\mathcal{S}=\\{S_i|i=1,\u0026hellip;,n\\}$ of the object of interest, the formulation of the problem takes the following form: $$ (x_i, \\theta_i)=\\arg\\max_{\\mathrm{x}_i,\\theta_i}p(\\mathrm{x}_i,\\theta_i|I,\\mathcal{S}),i=1,\u0026hellip;,n $$ The number of instances $n$ is apriori known by the methods.\nCategory-level pose estimation # Single instance per category # Given an instance $C$ of an interested category $c$, the 6D object pose estimation problem is formulated at the level of categories:\n$$ (\\mathrm{x}, \\theta)^*=\\arg\\max_{\\mathrm{x}, \\theta}p(\\mathrm{x},\\theta|I,C,c) $$ This equation assumes that there is only one instance of the interested category in the RGB-D image $I$ (apriori known by any 6D object pose estimation method).\nTODO: 所以这个方法是能通过 category c 找到 instance C 的位置吗？并需要不知道 instance C 到底是什么？\nMulti-instances per category # In case the image $I$ involves multiple instances $\\mathcal{C}=\\{C_i|i=1,\u0026hellip;,n\\}$ of the category of interest:\n$$ (\\mathrm{x}_i, \\theta_i)^*=\\arg\\max_{\\mathrm{x}_i, \\theta_i}p(\\mathrm{x}_i,\\theta_i|I,\\mathcal{C},c) $$\nChallenges # Note that the instances\u0026rsquo; challenges can also be observed at the level of categories, but not the other way round.\nChallenges of instances # Viewpoint variability 视点变化 # viewpoint variability 和 pose space variability 实际上是相对的。毕竟 camera 所在 viewpoint 的变化和物体的 pose 变化本质上是相对运动。而不同的 viewpoint 观察到的物体的形状可能具有很大差异。\nTexture-less objects # Texture is an important information for RGB cameras. An object of interest can easily be distinguished from background or any other instances available in the scene, in case it is sufficiently textured. The texture on the surface allows to define discriminative features to represent the interested object. However, when objects are texture-less, this discriminative property disappears, and thus making methods strongly dependent on depth channel in order to estimate 6D poses of objects.\n纹理方便用来区分 object of interest 和背景+其他物体。如果没有纹理，那么只能依靠深度信息来区分了。\nOcclusion 遮挡 # Occlusion occurs when an object of interest is partly or completely blocked by other objects existing in the scene.\nClutter 混乱 # Clutter is a challenge mainly associated with complicated background of images, in which existing objects of interest even cannot be detected in naked eyes（不过这个就太苛刻了吧）\nSimilar-Looking Distractors # 当缺乏一些 discriminative features 时，6D pose estimator 容易做出误判。\nChallenges of categories # Intra-class variation # Despite the fact that instances from the same category typically have similar physical propertities, they are not exactly the same.\nTexture and color variations are seen in RGB channel, geometry and shape discrepancies are observed in depth channel.\nGeometric dissimilarities are related to scale and dimensions of the instances, and shape-wise, they appear different in case they physically have extra parts out of the common ones.\n尽管相同类别的物体确实有共同的物理属性，但是它们并非完全一致。比如：纹理和颜色的区别可以由 RGB 的值观测到，而几何与形状的区别可以由 depth 信息观测到。\n几何上的区别主要和物体的不同尺寸有关（比如小杯子和大杯子），而形状上的区别主要来源于不同物品除了共同的部分会有一点小区别。\nDistribution shift # The objects in the target domain are different than that are of the source domain, there is a shift between the marginal probability distributions of these two domains.\nAdditionally, this distribution shift itself also changes as the instances in the target domain are unseen to the 6D pose estimator.\n物品在 source domain 上的分布会和在 target domain 上的有偏差（shift），并且 target domain 中的物品对 estimator 来说是未知的，所以观测到的 shift 会随着 target domain 中的实际物品变化。\nMulti-hypothesis issue # 对于某一个特定角度的 view，可以对物体的 pose 做多种合理假设。比如(a)中的碗，由于是对称的，所以多种 orientation 都合理；又比如当(b)中的杯子的把被遮挡时，这个杯子的 orientation 也可以做多种合理假设。\n"},{"id":3,"href":"/post/2023-06-12-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","title":"操作系统之进程与线程模型","section":"Posts","content":" 进程与线程模型 # 进程 # 进程的定义：进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的独立单位。\n进程状态 # 进程的基本状态：运行态、就绪态、等待态\n运行：占有 CPU，并在 CPU 上运行\n就绪：已经具备运行条件，但由于没有空闲 CPU，而暂时无法运行\n等待/阻塞 (注意不是挂起)：因为等待某一事件（如完成 IO）而暂时不能运行\n进程的其他状态 # 创建：已完成创建一进程所必要的工作。如分配了 PCB，拥有 PID。但未同意执行该进程，因为资源有限。\n终止：终止执行后，进程进入该状态。可以完成一些数据统计工作，并进行资源回收。\n挂起：把一个进程从内存转到磁盘。进程不占用内存空间，其进程映像（但不包括进程的代码段和数据段）交换到磁盘上。用于调节负载。\n就绪挂起：suspended ready\n阻塞挂起：suspended block\n下面摘自：https://www.orzzone.com/process-state-transition.html\n引入挂起状态后，需要实现进程在挂起（即在外存）状态和非挂起（即在内存）状态之间的转换。由于被挂起的进程不能被调度运行，因此通常将挂起状态称为静止状态，而将非挂起状态称为活跃状态。根据挂起前进程所处的状态，可以将挂起状态分为：静止就绪状态和静止阻塞状态。\n系统通常将具有相同状态的进程组成一个或多个队列。为了区别，将进程基本状态中的就绪状态改称为活动就绪状态，阻塞状态改称为活动阻塞状态。相应地，我们又多了 6 种转换关系：\n活动阻塞状态挂起变为静止阻塞态。主要有两种情况会发生这种挂起（进程由内存换出至外存）状态变化：①若当前不存在活动就绪进程，则至少有一个活动阻塞进程由内存兑换至外存成为静止阻塞进程，以腾出内存空间，从外存调入一个静止就绪进程使其变为活动就绪进程（保证内存中至少有一个活动就绪进程，可供进程调度程序调度运行以免CPU空闲）；②操作系统根据当前的资源状态和性能要求，可以将某些活动阻塞进程换出至外存成为静止阻塞进程。 静止阻塞态激活变为活动阻塞态。一般在满足两个条件下，系统可以激活（进程由外存换入至内存）一个静止阻塞态进程，使之成为活动阻塞进程。即：①操作系统已经得知导致该进程阻塞的事件即将结束；②内存中已经有了一大块空闲的空间。 静止阻塞态变为静止就绪态。当在外存上的静止阻塞进程所需资源得到满足或者等待的事件已经完成时，该进程由静止阻塞态变为静止就绪态（但仍然在外存）。 静止就绪态激活变为活动就绪态。主要有三种情况会发生这种激活（进程由外存换入至内存）状态变化：①外存上的静止就绪进程具有比内存中的活动就绪进程更高的优先级；②内存中已经有了一大块空闲的空间；③当前内存中没有活动就绪进程。 活动就绪态挂起变为静止就绪态。这种状态变化主要是由于系统调节负荷（即内存紧张）的需要，或者是系统优化性能的需求，而将某些目前暂不需要运行的活动就绪进程由内存换出至外存。 运行态挂起（由内存换出至外存）变为静止就绪态。这种状态变化制药是运行进程出现了错误或异常，或者是对运行进程进行分析的需要。 可见，只有处于活动就绪态的进程，才能参与进程调度得到CPU，并在获得CPU后立即投入运行。具有挂起状态的系统虽然提高了内存的利用率，但同时也使管理更加复杂，且增加了系统的开销。\n进程控制块 PCB（Process Control Block） # 操作系统表示进程的一个专门的数据结构，记录进程的各种属性，描述进程的动态变化过程。\n又称为：进程描述符、进程属性\n操作系统通过 PCB 来控制和管理进程\nPCB 是系统感知进程存在的唯一标志 进程与 PCB 是一一对应的 Linux：task_struct\nWindows: EPROCESS, KPROCESS, PEB\nPCB 的主要内容\n进程描述信息 进程标识符 进程名，通常基于可执行文件名 用户标识符；进程组关系 进程控制信息 当前状态；阻塞原因 优先级 代码执行入口地址 可执行文件名（磁盘地址） 运行统计信息（执行时间页面调度） 进程间同步和通信 进程的队列指针 进程的消息队列指针 所拥有的资源和使用情况 虚拟地址空间的现状 打开文件列表 CPU 现场信息 寄存器值（通用寄存器、PC、PSW、栈指针） 指向赋予该进程的段/页表的指针 进程地址空间 # /proc/{pid}/maps 文件\n显示进程映射了的内存区域和访问权限 在内核中，进程的一段地址空间用 vm_area_struct 表示，所有地址空间存储在 task-\u0026gt;mm-\u0026gt;mmap 链表中 一个文件可以映射到进程的一段内存区域中，映射的文件描述符保存在 vm_area_struct-\u0026gt;vm_file，这种内存区域叫做有名内存区域，另一个是匿名映射内存区域 上下文 # 进程运行时，其硬件状态保存在 CPU 上的寄存器中\n寄存器：程序计数器、程序状态寄存器、栈指针、通用寄存器、其他控制寄存器\n进程不运行时，这些寄存器的值都保存在 PCB 中（xv6 中叫 trapframe）\n将 CPU 硬件状态从一个进程切换到另一个进程的过程称为上下文切换。（但注意，切换的时候进程的地址空间对应的那些物理内存还是驻留在内存的，除非为了腾出内存空间被挂起而交换到硬盘）\n进程队列 # 操作系统为每一类进程建立一个或者多个队列。队列的元素为 PCB。伴随进程状态的改变，其 PCB 从一个队列进入另一个队列。\n进程控制 # 进程控制操作完成进程各状态间的转换，由具有特定功能的原语完成\n原语（primitive）：完成某种特定功能的一段程序，具有不可分割性或不可中断性。即原语的执行必须是连续的，在执行过程中不允许被中断。\n进程创建 # Unix：fork, exec, spawn\nWindows: CreateProcess\n进程撤销 # Unix: exit\nWindows: ExitProcess\n进程阻塞和进程唤醒 # 处于运行状态的进程，在其运行过程中期待某一事件发生，如等待键盘输入、等待磁盘数据传输完成、等待其它进程发送消息，当被等待的事件未发生时，由进程自己执行阻塞原语，使自己由运行态变为阻塞态。\nUnix：wait\nWindows：WaitForSingleObject\nUnix 的几个进程控制操作 # fork() # 通过复制调用进程来建立新的进程，是最基本的进程建立过程\n为子进程分配一个空闲的进程描述符\n分配给子进程一个唯一标识 pid\n以一次一页的方式复制父进程地址空间（可以用 COW 优化）\n从父进程处继承共享资源，如打开的文件和当前工作目录等\n将子进程的状态设为就绪，插入到就绪队列\n对子进程返回标识符 0\n向父进程返回子进程的 pid\nCOW 机制：\n在 fork 时，子进程的 page table 与父进程完全一致。并且将每个可写页面标记成 COW 页面，同时记录每个页面的引用次数。\n如果任一进程想要更改页面的内容，并且该页面是 COW 的，那就应该为这一页新分配内存，将之前的页表项的映射关系取消，页面引用数减1。在某进程退出时，如果遇到有页面的引用数大于1，则该物理页面不释放。\nexec() # 包括一系列系统调用，它们都是通过用一段新的代码覆盖原来的内存空间，实现进程执行代码的转换\nwait() # 提供初级的进程同步措施，能使一个进程等待，直到另外一个进程结束为止。\nAll of these (wait/waitpid/waitid) system calls are used to wait for state changes in a child of the calling process, and obtain information about the child whose state has changed. A state change is considered to be: the child terminated; the child was stopped by a signal; or the child was resumed by a signal exit() # 用来终止一个进程的运行\n问题：Linux 中什么是 zombie 进程？什么是 orphan 进程？\n下面摘自：https://en.wikipedia.org/wiki/Zombie_process\nOn Unix and Unix-like computer operating systems, a zombie process or defunct process is a process that has completed execution (via the exit system call) but still has an entry in the process table: it is a process in the \u0026ldquo;Terminated state\u0026rdquo;. This occurs for the child processes, where the entry is still needed to allow the parent process to read its child\u0026rsquo;s exit status: once the exit status is read via the wait system call, the zombie\u0026rsquo;s entry is removed from the process table and it is said to be \u0026ldquo;reaped\u0026rdquo;. A child process always first becomes a zombie before being removed from the resource table. In most cases, under normal system operation zombies are immediately waited on by their parent and then reaped by the system – processes that stay zombies for a long time are generally an error and cause a resource leak, but the only resource they occupy is the process table entry – process ID.\n也就是说，zombie 进程已经终止（die）了、但是没来得及由父进程确认其退出状态。（not reaped）\nWhen a process ends via exit, all of the memory and resources associated with it are deallocated so they can be used by other processes. However, the process\u0026rsquo;s entry in the process table remains.\n因为 zombie 进程已经调用过 exit，所以它拥有的内存和其他资源都被释放了。只占有 PID。\nZombie processes should not be confused with orphan processes: an orphan process is a process that is still executing, but whose parent has died. When the parent dies, the orphaned child process is adopted by init (process ID 1). When orphan processes die, they do not remain as zombie processes; instead, they are waited on by init. The result is that a process that is both a zombie and an orphan will be reaped automatically.\norphan 进程是还在执行，但父进程已经终止了的进程。当父进程终止后，init 进程会成为 orphan 进程的父进程托管它。\n线程 # 进程的两个基本属性\n资源的拥有者 一个虚拟地址空间，一些占有的资源(文件，I/O设备) 调度单位 一个执行（路径）轨迹，状态、优先级 将原来进程的两个属性分别处理 线程：进程的一个运行实体，是 CPU 的调度单位 线程共享的内容包括：\n进程代码段 进程数据段 进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户 ID 与进程组 ID\n线程独有的内容包括：\n线程 ID 寄存器组的值 线程的堆栈：有自己的栈和栈指针 错误返回码 线程的信号屏蔽码\n线程的实现 # 用户级线程：在用户空间实现\n核心级线程：在内核中实现\n混合两者：在内核中实现，支持用户线程\n用户级线程 # 优点：\n线程切换快 调度算法是应用程序特定的 用户级线程可以运行在任何 OS 上（只需要实现线程库） 缺点：\n大多数系统调用是阻塞的，因此，由于内核阻塞进程，故进程中所有线程也被阻塞 内核只将处理器分配给进程，同一进程中的两个线程不能同时运行于两 个处理器上 核心级线程 # 混合模型 # 线程创建在用户空间完成\n线程调度等在核心态完成\n多个用户线程多路复用多个内核级线程\n用户线程、内核线程、LWP 三者之间的关系 # 协程 # 这部分内容来自：https://www.cnblogs.com/Survivalist/p/11527949.html#%E5%8D%8F%E7%A8%8B\n协程，英文Coroutines，是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做『用户空间线程』，具有对内核来说不可见的特性。\n因为是自主开辟的异步任务，所以很多人也更喜欢叫它们纤程（Fiber），或者绿色线程（GreenThread）。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。\n笔者的疑惑：协程好像就是开了历史的倒车（？），其实就是程序员自主实现的用户空间的线程，不受操作系统的调度，因而开销更小。\n"},{"id":4,"href":"/post/2023-06-11-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6/","title":"操作系统之异常处理机制","section":"Posts","content":" 异常处理 # 寄存器 # 处理器由运算器、控制器、一系列的寄存器以及高速缓存构成。\n用户可见寄存器：机器语言可以直接引用\n数据寄存器：也称为通用寄存器 地址寄存器：地址寄存器可以分为两种类型：一种是基地址寄存器，它存储的是变量或数组的起始地址; 另一种是偏移地址寄存器，它存储的是相对于基地址的偏移地址。 条件码寄存器：条件码（condition code）寄存器，是 CPU 维护的一组单个位的用于描述最近的算术或逻辑操作的状态属性，条件分支指令可以检测这些寄存器的值来确定转移方向,最常用的条件码有: CF（进位标志）、ZF（零标志）、SF（符号标志）、OF（溢出标志） 控制和状态寄存器：用于控制处理器的操作，在某种特权级别下可以访问和修改\n程序计数器（PC）：用来存储指向下一条指令的地址 指令寄存器（IR：instruction register）：用于取指后暂存当前正在执行的指令 程序状态字（PSW：program status word）：PSW用来存放两类信息：一类是体现当前指令执行结果的各种状态信息，称为状态标志，如有无借位进位（CY位）、有无溢出（OF位）、结果正负（SF位）、结果是否为零（ZF位）、奇偶标志位（PF位）等；另一类是存放控制信息，称为控制状态，如允许中断(IF位)，跟踪标志（TF位），方向标志(DF)等。有些机器中将PSW称为标志寄存器FR（Flag Register）。 比如 x86 的 FLAGS 寄存器：\n低 16 位是 FLAGS\n中间 16 位是 EFLAGS\nIOPL：I/O 特权级\nNT：嵌套任务标志\nRF：重新启动标志\nAC：对准检查方式位\nVIF：虚拟中断标志\nVIP：虚拟中断 pending 标志\nID：The ID flag (bit 21) in the EFLAGS register indicates support for the CPUID instruction. If a software procedure can set and clear this flag, the processor executing the procedure supports the CPUID instruction. This instruction operates the same in non-64-bit modes and 64-bit mode.\n特权指令和非特权指令 # 操作系统需要至少两种 CPU 状态\n内核态 用户态 X86 支持 4 个处理器特权级别（特权环）：R0 到 R3，特权能力由高到低；R0 相当于内核态，R3 相当于用户态；R1 和 R2 介于两者之间。不同特权态能够运行的指令不同。\nRISC-V 支持 3 个处理器特权模式：\nMachine Supervisor User CPU 状态之间的切换\n用户态➡️内核态：唯一途径是中断、异常、陷入机制（通过陷入/访管指令，例如 int, trap, syscall, sysenter/sysexit, ecall） 内核态➡️用户态：设置程序状态字 PSW 的特权态位 中断机制 # 操作系统是由“中断驱动”或 “事件驱动”的\n事件：\n中断（interrupt）：又叫外中断，为了支持 CPU 和设备之间的并行操作。如 I/O 中断、时钟中断、硬件故障。\n异常（exception）：表示 CPU 执行指令时本身出现的问题。如系统调用、页错误/页故障、保护性异常、断点指令、其他程序性异常\nunexpected deliberate exception（sync） fault syscall trap interrupt（async） interrupt software interrupt 类别 原因 异步/同步 返回行为 中断interrupt 来自I/O设备、其他硬件设备 异步 总是返回到下一条指令 陷入 trap 有意识安排的（如系统调用） 同步 返回到下一条指令 故障 fault 可恢复的错误 同步 返回到当前指令 终止 abort 不可恢复的错误 同步 不返回 硬件负责中断/异常的响应：\n捕获中断源发出的中断/异常请求，以一定方式响应，将处理器控制权交给特定的处理程序\n下面关于80386 处理器中断检测机制参考：https://segmentfault.com/a/1190000040630593\n（接图中红字）但这么多外设，只有一个引脚。因此需要为添加一个可编程中断控制器 PIC，外部设备的中断通过它进入 CPU，所以它负责从外设接收中断信号，并根据优先级向 CPU 发起中断请求。最开始这个 PIC 是 8258A 芯片。\n其中 IR0-IR7 共8个引脚负责连接外部设备， 8259A PIC 的每个 IR 口都连接着一条 IRQ 线，用于接收外设的中断信号。INT 负责连接 CPU的 INTR 引脚，用于向 CPU 发起中断请求。通常情况下，使用两片8259A 芯片进行级联，一片连接 CPU，称为主片，另一片连接到主 PIC 的 IR2 引脚，称为从片，这样总共就可以连接 8+7=15 个外设了。\n如图所示：\n在 8259A 中，默认情况下的优先级是主片IR0的中断请求优先级最高，主片IR7最低，从片 IR0-7 所有中断请求优先级都相当于 IR2。所以IRQ线的优先级由高到低次序为 IRQ0，IRQ1，IRQ8-15，IRQ3-7。这是默认情况，可以通过编程改变。\n在 8259A 中有几个重要的寄存器：\n中断请求寄存器: IRR，8bit，对应 IR0-IR7，当对应引脚产生中断信号时，该位置1。\n中断服务寄存器: ISR，8bit，对应 IR0-IR7，当对应引脚的中断正在被CPU 处理时，该位置1。\n中断屏蔽寄存器: IMR，8bit，对应 IR0-IR7，当对应位为1时，表示屏蔽该引脚产生的中断信号。\n还有一个中断优先级判决器: PR，当中断引脚有信号时，结合这次产生中断的 IRQ 号和 ISR 中记录的当前正在处理的中断信息，根据优先级来决定是否把这个新的中断信号报告给 CPU，以此来产生中断嵌套。\n现在假设我们敲击了一个键盘按键，键盘有中断事件产生，这一事件通过 IRQ1 这根线告知了主 PIC，主 PIC 经过内部一些判断处理后通过INT 发送电信号到 CPU 侧的 INTR。CPU在执行完当前的指令后，检查到 INTR 有信号，说明有中断请求来了，再检查 eflags 中的 IF 不为零，表示当前允许中断，则发送信号给 PIC 的 INTA，告诉它把本次中断的向量号发送过来。主 PIC 收到 INTA 管脚上的信号后，通过 D0-D7引脚，输出此次中断的中断向量号到数据总线（这里简化了交互过程，实际上有两次 INTA 信号的发送）。CPU 拿到这个号后，就可以从中断描述符表（IDT）中寻找中断服务例程（ISR）进行处理了，后面的事大家都知道了。\n中断向量表：\n中断向量表就是中断向量的列表。\n中断向量表在内存中保存，其中存放着 256个中断源所对应的中断处理程序的入口地址。 对于 8086 系统，中断向量表在内存中最低端 1K 字节空间。\n软件负责中断/异常处理：\n识别中断/异常类型并完成相应的处理（调用中断处理程序）\nLinux x86 中的中断向量：\n几个重要的点：0x80 用于系统调用，14 用于缺页异常。\n中断响应流程：\n设备发中断信号 硬件保存现场（注意，RISC-V 无此机制，需要 OS 处理） 根据中断码查询中断向量表 把中断处理程序入口地址推送到相应的寄存器（PC） 执行中断处理程序 RISC-V 硬件的中断相应流程：\nCPU 会做如下处理：\nCPU 将停止执行当前的程序流，转而跳转（实际上就是更新 PC 寄存器的值）到 stvec 寄存器定义的 PC 地址开始执行 在 RISC-V 中，stvec（supervisor trap vector base address register，中断向量表基址寄存器）把最低位的两个二进制位用来编码一个“模式”，如果是“00”就说明更高的 SXLEN-2 个二进制位存储的是唯一的中断处理程序的地址(SXLEN是stval寄存器的位数)，如果是“01”说明更高的 SXLEN-2 个二进制位存储的是中断向量表基址，通过不同的异常原因来索引中断向量表。但是怎样用62个二进制位编码一个 64 位的地址？RISC-V 架构要求这个地址是四字节对齐的，总是在较高的 62 位后补两个 0。因此如果只有几个中断处理程序，stvec 就是那个中断处理程序的地址。\n当我们触发中断进入 S 态进行处理时，以下寄存器会被硬件自动设置，将一些信息提供给中断处理程序：\nsepc(supervisor exception program counter)，它会记录触发中断的那条指令的地址（便于之后返回）\nscause，它会记录中断发生的原因，还会记录该中断是不是一个外部中断（便于索引具体的处理程序）\nstval，它会记录一些中断处理所需要的辅助信息，比如指令获取(instruction fetch)、访存、缺页异常，它会把发生问题的目标地址或者出错的指令记录下来，这样我们在中断处理程序中就知道处理目标了。stval 寄存器的另一个名称为 sbadaddr。\n如果是存储器访问造成的异常(例如取指令、硬件断点、存储器读写造成的异常)，则将存储器访问的地址更新到 stval 寄存器中。 如果是非法指令造成的异常，则将该指令的指令编码更新到 mtval 寄存器中。 sstatus，主要记录之前的中断使能位和之前的特权级，并设置现在的使能情况。\n注意：RISC-V 架构在进入退出异常机制中没有硬件自动保存和恢复上下文的操作。（所以需要软件上实现上下文切换的机制（具体表现为 OS 中的保存和恢复寄存器的汇编代码）\n问题：RISC-V CPU如何知道自己所处的当前特权态\n稍微了解 RISC-V 的读者可能会认为上述用两位二进制来编码的特权等级是写在某个 CSR 的字段中的（注意 mstatus 的 MPP 是之前的特权态），然而实际上 RISC-V 的设计人员没有开放一个“接口”让软件来得知当前正在处理器处于的特权等级（从硬件角度来讲，处理器中一定有某个“寄存器”记录着当前的特权等级状态，但这个“寄存器”没有暴露给软件层面）。他们认为软件开发人员应该准确地知道每段代码所处的特权等级，比如一般的应用程序处于 User 级别，而 OS 内核和驱动程序则处于 Supervisor 级别，而不同等级的中断处理函数则分别处于不同的等级。\n以设备输入输出为例：\n打印机给 CPU 发中断信号\nCPU 处理完当前指令后检测到中断，判断出中断来源并向相关设备发确认信号\nCPU 开始为软件处理中断做准备\n处理器状态被切换到内核态 在系统栈中保存被中断程序的重要上下文环境，主要是程序计数器 PC 和程序状态字 PSW CPU 根据中断码查中断向量表，获得与该中断相关的处理程序的入口地址。并将 PC 设置成该地址，新的指令周期开始时，CPU 控制转移到中断处理程序\n中断处理程序开始工作\n在系统栈中保存现场信息 检查 IO 设备的状态信息，操纵 IO 设备或者在设备和内存之间传送数据等 中断处理结束时，CPU 检测到中断返回指令，从系统栈中恢复被中断程序的上下文环境，CPU 恢复到原来的状态，PSW 和 PC 都恢复到中断前的值，CPU 开始新的指令周期\nIA32 体系结构对中断的支持 # 英特尔32位架构（英语：Intel Architecture, 32-bit，缩写为 IA-32），常被称为 i386、或 x86，由英特尔公司于 1985 年推出的指令集架构。它是 8086 架构的延伸版本，可支持32位运算，首次应用在Intel 80386芯片中。\n中断控制器 # （PIC 或者 APIC）\n负责将硬件的中断信号转换为中断向量，引发 CPU 中断\n实模式（Real-Address Mode）：中断向量表（interrupt vector table, IVT） # 存放中断服务程序的入口地址\nIn real-address mode, the only system data structure that must be loaded into memory is the IDT (also called the “interrupt vector table”). By default, the address of the base of the IDT is physical address 0H\n入口地址=段地址左移4位+偏移地址\n不支持 CPU 运行状态切换\n中断处理与一般的过程调用相似\n问题：什么是 Real-Address Mode？下面的内容摘自 Intel System Programming Guide：\nThe execution environment of the processor in real-address mode is designed to duplicate the execution environ- ment of the Intel 8086 processor. To an 8086 program, a processor operating in real-address mode behaves like a high-speed 8086 processor.\nAddress Translation in Real-Address Mode\nIn real-address mode, the processor does not interpret segment selectors as indexes into a descriptor table; instead, it uses them directly to form linear addresses as the 8086 processor does. It shifts the segment selector left by 4 bits to form a 20-bit base address (see Figure 21-1).\n保护模式（Protected Mode）：中断描述符表（Interrupt Descriptor Table） # IDT: Interrupt Descriptor Table\nThe interrupt descriptor table (IDT) associates each exception or interrupt vector with a gate descriptor for the procedure or task used to service the associated exception or interrupt. Like the GDT and LDTs, the IDT is an array of 8-byte descriptors (in protected mode).\nIDTR: Interrupt Descriptor Table Register\n系统调用 # 系统调用的参数传递过程\n由陷入指令自带参数：陷入指令的长度有限，且还要携带系统调用功能号，只能自带有限的参数 通过通用寄存器传递参数：这些寄存器是操作系统和用户程序都能访问的，但寄存器的个数会限制传递参数的数量 在内存中开辟专用堆栈区来传递参数 例：Linux 系统调用 # 系统执行 int $0x80 指令后 OS 的操作 # 由于特权级的改变，要切换栈：用户栈➡️内核栈\nCPU 要从任务状态段 TSS 中装入新的栈指针（SS：ESP），指向内核栈\n用户栈的信息（SS：ESP）、EFLAGS、用户态代码段寄存器 CS、EIP 寄存器（就是 PC 寄存器）的内容压栈\n将 EFLAGS 压栈后，复位 TF，IF 保持不变\n用 128 在 IDT 中找到该门描述符，从中找出段选择符装入代码段寄存器 CS\n代码段描述符中的基地址+陷阱门描述符中的偏移量➡️定位system_call()的入口地址\n参数传递 # 使用寄存器传递参数，要传递的参数包括：\n系统调用号 系统调用所需的参数 用于传递参数的寄存器：\neax 用于保存系统调用号和系统调用的返回值 系统调用参数保存在 ebx, ecx, edx, esi 和 edi 中 进入内核态后，system_call 再将这些参数保存在内核的堆栈中\n"},{"id":5,"href":"/post/2023-06-04-%E8%8A%B1%E6%A0%B7%E6%BB%91%E5%86%B0%E7%A7%AF%E5%88%86%E8%A7%84%E5%88%99/","title":"花样滑冰积分规则","section":"Posts","content":"本文参考：https://www.tumblr.com/the-real-xmonster/172317267829/world-standing-how-does-it-work-i-got-several\nISU World Standing # 最近因为作业的缘故，需要了解国际滑联（ISU）给花样滑冰运动员积分排名的方式。从 ISU 的官方页面知道有两个比较重要的排名，分别是 ISU World Standing, ISU World Season\u0026rsquo;s Ranking\n这两个排名中比较重要的是 ISU World Standing，为什么呢？这是因为国际滑联会根据这个排名确定花滑世锦赛上短节目（short program）比赛的顺序。分数最高的 6 名选手将在最后一组出场（不过，这 6 个人的确切出场顺序将抽签决定）。\nISU World Standing 是积分制的排名系统，综合考察了过去三个赛季的积分。每个赛季为期一年，如2020-2021年为一个赛季。最近两年的积分按照原始积分计算，而最远的那个赛季的积分要乘70%，进行削弱。\n下面我们介绍每个赛季的积分如何计算。每个赛季的积分取决于两个因素：选手参加了什么类型的比赛，以及在比赛中获得的排名。\n比赛共有三个档次：\n档次1: 冬奥会，世锦赛，欧洲锦标赛，四大洲锦标赛 档次2: 花滑大奖赛的六个分站赛（Grand Pix）和总决赛（Grand Pix Final） 档次3: 所有其他 ISU 认可的国际个人比赛 ISU 给每种类型比赛的评分如下：\n但是，上表中的 IC（international competitions）并不适用于挑战者系列赛事（ISU Challenger Series）。这个系列的比赛比一般的 IC 比赛评定的分数更高，但是又比大奖赛低。\n最佳积分原则 # 对档次1的比赛，只有该赛季的最佳成绩才被统计。比如，陈巍在2017-2018赛季的积分是1200，因为他在世锦赛取得了冠军。他在冬奥会上的积分是787（第五名），但因为比世锦赛的成绩更低，所以不被记入。\n对档次2和档次3的比赛，取最高的两次成绩之和。注意，最高成绩是从积分来说的，而不是排名高低。\n最终积分 # 对于档次1比赛的积分，选择过去三个赛季中最好的2次成绩。\n对于档次2/3比赛的积分，选择过去三个赛季中最好的4次成绩。\n然后将挑选出来的这些积分相加，就得到了他们的总积分，再根据这个积分排名，可以得到他们的 World Standing。\n以羽生结弦在2017-2018年的 World Standing 为例：\n2017-2018 season points（100%）：\n档次1：1200（冬奥会 1st）\n档次2：最佳，360（GP Rostelecom Cup 2nd）；次佳，无\n档次3：最佳，270（Autum Classic Intl, Challeng Series, 2nd）；次佳，无\n2016-2017 season points（100%）：\n档次1：1200（世锦赛 1st）\n档次2：最佳，800（GP Final, 1st）；次佳，400（GP JPN Cup, 1st）\n档次3：最佳，300（Autum Classic Intl, Challeng Series, 1st）；次佳，无\n2015-2017 season points（70%）：\n档次1：756（世锦赛 2nd）\n档次2：560（GP Final, 1st）；次佳，280（GP JPN Cup，1st）\n档次3：175（Autum Classic Intl, Challeng Series, 1st）；次佳，无\n综上：\n档次1: 1200+1200 档次2: 800+560+400+360 档次3: 300+270+175 最终成绩：5265\nISU World Season\u0026rsquo;s Ranking # 对于每个赛季的排名，就是用上述算法算出每个赛季的积分，比如羽生结弦在2017-2018赛季的积分是1200+360+270=1830。\n"},{"id":6,"href":"/post/2023-06-03-%E8%8A%B1%E6%A0%B7%E6%BB%91%E5%86%B0%E6%8A%80%E6%9C%AF%E5%85%83%E7%B4%A0%E4%B9%8B%E8%B7%B3%E8%B7%83/","title":"Figure skating elements (jump)","section":"Posts","content":"以下内容来自：https://www.youtube.com/watch?v=HkcAmGCkjtA\n基本规律 # Every jump is landed in the same way, so you look at the entrance of the jump to tell them apart.\n所有的跳跃在落地时使用的都是同一方式。所以通过进入跳跃的方式来区分不同的跳跃。\n对于右撇子来说，在空中的旋转一般是逆时针的。如果一位运动员在空中的旋转是顺时针的，那么他所有的动作的左右都和其他运动员相反。\nall jumps land on the right back outside edge\n所有的跳跃都在 right back outside edge 落地。\nright：右脚 back：向后滑行 outside：冰刀外侧 edge：冰刃 下面是演示图：\n两种类型：点冰跳，结环跳 (2 categories: toe jumps, edge jumps) # Toe jumps: Toe Loop, Flip, Lutz\nEdge jumps: Salchow, Loop, Axel\n后外点冰跳 Toe Loop # entered from a turn or as the 2nd/3rd jump in combination（因为只有 turn 或者前面的 jump 结束之后，左脚才会在后面，才可能左脚尖踮地跳起） strike the ice with the left toe pick In high-level ladies skating, the toe loop is almost always used as the and/3rd jump in a combo, never on its own except for the VERY few women who can do a Quad Toe Loop 要注意，点冰脚不是起跳脚。因此右脚起跳，右脚落冰。 后内点冰跳 Flip Loop # entered from a turn left back inside edge (maybe a shallow inside edge, especially for women) right toe pick strikes the ice 左脚起跳，右脚落冰 勾手跳 Lutz # usually entered from a longer, straight backwards glide left back outside edge（因为脚要往外撇一下，看起来像是崴脚了） right toe pick strikes the ice 左脚起跳，右脚落冰 后内结环跳 Salchow # entered from a turn No toe pick assistance \u0026ldquo;sweeping\u0026rdquo; motion of blades Legs form / \\ shape take off from left blade（从左刃起跳） 左脚起跳，右脚落冰 后外结环跳 Loop # often entered from a turn left leg crossed over right leg in X shape take off from right blade can also be used as 2nd or 3rd jump in combination 右脚起跳，右脚落冰（所以 Loop 容易和 Toe Loop 弄混） 阿克塞尔跳 Axel # the only jump that takes off forward 首先向后滑动，然后看向左侧 and then, left foot steps forward, draw back arms, lift right leg（借力） and jump (take off from the left blade) because it takes off forward and lands backward, the axel has an extra half rotation (相当于正面起跳，落地时是背面，多出半圈) 左脚起跳，右脚落冰 Euler # (pronounced \u0026ldquo;oiler\u0026rdquo;)\n(Formerly known as Single Loop or Half Loop)\nSkaters can do a 3-jump combination with an Euler as the 2nd jump, and a Salchow or Flip as the 3rd jump\nAn Euler is a single-revolution jump that takes off from the right back outside edge and lands on the left back inside edge. Then you can do a jump that takes off from the LBI, eight the Salchow or Flip.\n因为 Euler 将 RBO 转换为 LBI，因此可以在组合中接左脚（内刃）起跳的跳跃。由于 Lutz 需要助滑，所以基本没有人将其用作第三跳。\n经验总结 # 由于在实际比赛中，如果不使用慢速设备很难观察到是否点冰，所以除了点冰外，还需要一些别的技巧判断跳跃方式。\n向前行进过程中跳跃一定是 Axel。并且跳跃前选手左脚上步，右脚会抬起并且有很夸张的借力动作。 （对于选择 counterclockwise loop 的选手）右脚起跳的（如果不好判断转向，那么同一只脚起跳+落地的）一定是 Toe Loop 或者 Loop，因此这两种滑动很难区分。但 Loop 在起跳前双腿交叉呈 X 状。并且由于 T 和 Lo 右脚起跳，所以经常被用作组合里的第二跳。 Euler 跳后一定是 Salchow 或者 Flip。Salchow 起跳前双腿呈八字状。 Lutz 左外刃起跳，因此看起来像是崴了脚。而且 Lutz 需要向后的长助滑。 后外点冰跳(T)/后外结环跳(Lo)，后内点冰跳(F)/后内结环跳(Salchow)均不易区分。 最后附上维基百科的速查表格：\n"},{"id":7,"href":"/post/2023-05-26-%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","title":"区块链相关概念解释","section":"Posts","content":" 注意：本文仅作技术概念解释，并不输出任何主观投资意见。\n本文主要按照以下逻辑组织：\n区块链 blockchain、比特币 bitcoin、以太坊 ethereum、智能合约 smart contract、去中心化应用 DApp、代币 token、共识机制 consensus mechanism（内容较多，预计开一篇新的 post 来总结） ERC20 BRC20 区块链 # 从抽象的角度来讲，区块链是一个分布式“账本”。分布式是指区块链是由许多对等的节点（node）共同构成；账本的比喻是指区块链就像一个大账本，存储了每一项交易的信息；至于为什么叫做“区块”“链”，是因为多个交易（transaction）的执行会形成一个新的区块（block）来保存交易信息，而这些区块以链（chain）的形式连接起来（类似计算机数据结构中的链表），实际上，每个区块都记录了它前一个区块的唯一哈希标识（hash），而当前区块的标识则由时间戳、前面区块的标识和当前区块的内容共同计算得到。如果区块的内容被矿工（miner）核验（verify，其实就是挖矿，具体操作将在后面的“共识机制”部分解释）通过，那么新区块就会诞生并连接到区块链上（这个过程也成为“上链”）。\n因此，一旦有人改动了链上区块的内容，该区块及其所有后继区块的标识会“失效”（如何定义“失效”将在后面的“共识机制”部分进行解释），可能导致分布式环境中该节点被认为是出错或恶意节点，被排除出去。\n一个形象的在线 demo，可以帮助理解区块链：\nhttps://andersbrownworth.com/blockchain/blockchain\n区块链分叉 # 因为区块链是去中心化的数据结构，所以不同副本之间不能总是保持一致。区块有可能在不同时间到达不同节点，导致节点有不同的区块链视角。解决的办法是，每一个节点总是选择并尝试延长代表累计了最大工作量证明的区块链，也就是最长的或最大累计难度的链。节点通过将记录在每个区块中的难度加总起来，得到建立这个链所要付出的工作量证明的总量。只要所有的节点选择最长累计难度的区块链，整个比特币网络最终会收敛到一致的状态。分叉即在不同区块链间发生的临时差异，当更多的区块添加到了某个分叉中，这个问题便会迎刃而解。\n从理论上来说，两个区块的分叉是有可能的，这种情况发生在因先前分叉而相互对立起来的矿工，又几乎同时发现了两个不同区块的解。然而，这种情况发生的几率是很低的。单区块分叉每周都会发生，而双块分叉则非常罕见。所以这里提到的区块链分叉是区块链的一种临时状态，最终分叉很大概率会消失。\n比特币将区块间隔设计为10分钟，是在更快速的交易确认和更低的分叉概率间作出的妥协。更短的区块产生间隔会让交易清算更快地完成，也会导致更加频繁地区块链分叉。与之相对地，更长的间隔会减少分叉数量，却会导致更长的清算时间。\n本节参考资料：\nUnderstanding Double-Spending and How to Prevent Attacks (investopedia.com)\nhttps://ethereum.org/en/developers/docs/intro-to-ethereum/\nhttps://www.8btc.com/books/261/master_bitcoin/_book/8/8.html\n比特币 # 挖矿奖励 # 矿工们通过为比特币网络提供算力来换取获得比特币奖励的机会。矿工们在挖矿过程中会得到两种类型的奖励：创建新区块的新币奖励，以及区块中所含交易的交易费。\n上面所述区块链需要有矿工核验区块内容并将区块上链，这个过程需要消耗算力。为了激励各计算节点进行计算，如果某计算节点成功核验区块内容并计算得到了该区块的 hash（挖矿），那么这个节点就会得到创建新区块的比特币奖励。\n矿工们同时也会获取交易费。每笔交易都可能包含一笔交易费，交易费是每笔交易记录的输入和输出的差额。在挖矿过程中成功“挖出”新区块的矿工可以得到该区块中包含的所有交易“小费”。目前，这笔费用占矿工收入的0.5%或更少，大部分收益仍来自挖矿所得的比特币奖励。然而随着挖矿奖励的递减，以及每个区块中包含的交易数量增加，交易费在矿工收益中所占的比重将会逐渐增加。在2140年之后，所有的矿工收益都将由交易费构成。\n注意，一个区块往往包含多个交易。区块链中的每个区块都包含了产生于该区块的所有交易，且以 Merkle 树表示（关于 Merkle 树的内容，可以参考 mastering bitcoin 书籍的 7.7 节）。而矿工从自己的内存中收集所有交易、准备打包区块时，如果发现某交易提供更多的交易费，那么就会将它作为本次打包优先考虑的交易记录。\n挖矿同时还保护着比特币系统的安全，防止欺诈交易，避免“双重支付”，“双重支付”是指多次花费同一笔比特币。该部分将在“共识机制”部分阐述。\n交易确认 # 一个区块产生后，并不会被立即信任。网络上的节点总是信任最长的区块链，当一条交易记录被打包进一个区块后，就有了一个“确认”，而在这个区块所在的链后面再加入一个区块，就是第二个确认，如此下去，如果一个交易有了 6 个确认，就认为这个交易已经确定了，会被永远记录在区块链中。6 个确认的理由是：每个确认就是一次挖矿过程，需要提供严格的计算，因此，这 6 个区块被同一个矿工创建的概率很低，所以一个矿工伪造交易不太可能。由于比特币区块的平均产生时间是 10 分钟，所以一个交易最快需要 1 小时左右才能保证成功。\n交易广播 # 比特币交易中没有过期、超时的概念，一笔交易现在有效，那么它就永远有效。然而，如果一笔交易只在全网广播了一次，那么它只会保存在一个挖矿节点的内存中。因为内存池是以未持久化的方式保存在挖矿节点存储器中的，所以一旦这个节点重新启动，内存池中的数据就会被完全擦除。而且，即便一笔有效交易被传播到了全网，如果它长时间未处理，它将从挖矿节点的内存池中消失。如果交易本应该在一段时间内被处理而实际没有，那么钱包软件应该重新发送交易或重新支付更高的矿工费。\n比特币链的硬分叉和软分叉 # 硬分叉：硬分叉是一种不支持向后兼容的软件升级方式。通常，这些情况发生在节点以与旧节点的规则冲突的方式添加新规则时。新节点只能与运行新版本的软件节点进行交互。结果，区块链发生了分裂，生产出两个单独的网络：一个按照旧规则运行，一个则按照新规则运行。\n软分叉：软分叉是支持向后兼容的软件升级方式，升级后的节点仍可以与未升级的节点进行交互。软分叉的升级方式通常是向程序中新添加了一条规则，该规则也不会与之前的旧规则发生冲突。\n本节参考资料：\nhttps://www.8btc.com/books/261/master_bitcoin/_book/7/7.html\nhttps://www.8btc.com/books/261/master_bitcoin/_book/8/8.html\nhttps://www.tangshuang.net/4097.html\nhttps://academy.binance.com/zh/articles/hard-forks-and-soft-forks\n以太坊 # 以太坊也是一种分布式“账本”技术。它是一个开源的去中心化计算架构，能执行称为智能合约的程序。它使用区块链来同步和存储系统状态，用名为以太（ether，ETH）的加密货币来计量和约束执行资源成本。\n以太坊的目的并不是数字货币支付网络。与具有有限脚本的比特币不同，以太坊被设计成一个通用可编程的区块链，它运行一个虚拟机（EVM），能够执行脚本代码，并且该脚本语言是图灵完备的。\n本节参考资料：\nhttps://github.com/ethereumbook/ethereumbook/blob/develop/01what-is.asciidoc\n智能合约 # 一个以太坊 帐户是一个具有以太币 (ETH) 余额的实体，可以在以太坊上发送交易。 帐户可以由用户控制（EOA，externally owned account），也可以作为智能合约部署（contract account）。\nEOA 拥有私钥，拥有私钥意味着有对账户资金或合约的控制权；合约账户拥有智能合约代码，但并没有私钥。合约账户像 EOA 一样有地址，还能像 EOA 一样发送和接收以太（ETH）。当一个交易的目的地址是合约的地址时，合约代码就会在 EVM 上运行，合约程序的输入是这个交易及其交易数据。\n本节参考资料：\nhttps://ethereum.org/zh/developers/docs/accounts/\nhttps://github.com/ethereumbook/ethereumbook/blob/develop/02intro.asciidoc\n去中心化应用 # 去中心化应用是智能合约概念的扩展。更宽泛地讲，一个 DApp 是构建在开放、分布式、点对点架构上的网络应用。\n一个 DApp 至少囊括：运行在区块链上的智能合约（作为后端）和 web 用户界面（作为前端）。\n许多 DApp 还拥有别的分布式组件，比如：\n分布式（或点对点）存储协议（和平台） 分布式（或点对点）消息传递协议（和平台） 本节参考资料：\nhttps://github.com/ethereumbook/ethereumbook/blob/develop/01what-is.asciidoc\n代币 # Token # 代币的英文是 token，来源于古代英语中的 tācen 一词，代表的是标志或符号。token 通常被用来指代私下发行的、有特殊用途的类币物品，这类物品本身并不具备什么内在价值，比如游戏币、折扣券等。在区块链的语境下，token 被认为是区块链上所有权的一种抽象，它能代表诸如资产、货币、访问权限一类的概念。\nFungibility # 维基百科对可替代性（fungibility）的解释是\nIn economics, fungibility is the property of a good or a commodity whose individual units are essentially interchangeable.\n当我们可以把某代币的基本单位替换成与之在价值或功能上没有任何区别的物品的时候，这种代币就称为可替代代币（fungible token）。\n严格来说，如果一个代币可以被溯源，那么它就不是完全可替代的。不可替代代币（non-fungible token, NFT）代表了一个独特的有形或无形物品，因此是不可替代的。每个 NFT 都与一个唯一标识关联。\n比特币就是一种可替代代币。注意以太和以太坊上的代币在不同的层次被支持。处理以太的逻辑在以太坊协议的层次就被定义了，而代币的逻辑则是被智能合约所定义，以太坊协议对代币一无所知。因此，为了在以太坊上发行代币，你需要创建新的智能合约，其包含所有权限、转移机制、访问权限等。一旦部署了这个智能合约，那么该合约按照你给出的定义，负责与此代币有关的所有操作。为了标准化这个过程，Fabian Vogelsteller 在 2015 年提出了第一个标准，命名为 Ethereum Request for Comments 20（ERC-20）。具体内容将在 ERC-20 部分进行说明。\n本节参考资料：\nhttps://github.com/ethereumbook/ethereumbook/blob/c5ddebd3dbec804463c86d0ae2de9f28fbafb83a/10tokens.asciidoc\nERC20 # ERC20 是为可替代代币的实现提出的标准，因此 ERC20 token 没有特殊属性。\nERC20 标准为实现代币的合约定义了一组通用接口，因此所有的 ERC20 token 可以用同样的方式使用。这组接口由一系列必须和可选的函数组成。\n如果用 Solidity 来编写，那么 ERC20 规范应该是这样：\ncontract ERC20 { function totalSupply() constant returns (uint theTotalSupply); function balanceOf(address _owner) constant returns (uint balance); function transfer(address _to, uint _value) returns (bool success); function transferFrom(address _from, address _to, uint _value) returns (bool success); function approve(address _spender, uint _value) returns (bool success); function allowance(address _owner, address _spender) constant returns (uint remaining); event Transfer(address indexed _from, address indexed _to, uint _value); event Approval(address indexed _owner, address indexed _spender, uint _value); } ERC20 有两个数据结构，并在 Solidity 中用 data mapping 来实现。\n保存 token 的余额，key 是所有者的 address。每次 token 的转移都会导致一个账户余额减少，而另一个账户的余额增加。 mapping(address =\u0026gt; uint256) balances; 保存配额。什么是配额？考虑以下场景：token 的所有者 Alice 允许 Bob 或者某合约账号从她的账户中转移一定数目的 token，这个数目就是配额。同样 mapping 来表示，主键是 owner，映射得到另一个 mapping，该 mapping 的 key 是 spender 的地址。 mapping (address =\u0026gt; mapping (address =\u0026gt; uint256)) public allowed; ERC20 的两个数据结构正好对应了两个不同的使用场景。\n单步交易。仅调用 transfer 函数，常用于钱包程序。如果 Alice 想要最多给 Bob 10 个 token，那么她的钱包就向这个 token 对应的 smart contract 的地址发送一笔交易，调用 transfer 函数，参数为 Bob 的地址和 10。\n两步交易。第一步，token 的所有者通过调用 approve 函数将对 token 的控制权委托给另外一个账号。第二步，这个账号调用 transferFrom 函数获得 token。两步交易在初始代币发行（Initial Coin Offering，ICO）时很常用，假如 Alice 想 ICO 发行 AliceCoin，那么她可以这么做：\n首先，Alice 需要创建一个 AliceCoin ERC20 代币的合约账户，这个账户负责发行 AliceCoin 到 Alice 的账户中。然后，Alice 创建一个 AliceICO 的合约账户，这个账户负责出售 AliceCoin 给其他账户。有了这两个合约账户后，Alice 首先调用 AliceCoin 合约中的 approve 函数，说明她允许 AliceICO 在配额内执行 AliceCoin 合约中的 transferFrom 函数。然后，Bob 给 AliceICO 支付了一些 ETH，AliceICO 定义了 ETH 到 AliceCoin 的汇率，随后 AliceICO 调用 AliceCoin 合约的 transferFrom 函数，指定将一定数目的 AliceCoin 从 Alice 的账户转移到 Bob 的账户。\n本节参考资料：\nhttps://eips.ethereum.org/EIPS/eip-20\nhttps://github.com/ethereumbook/ethereumbook/blob/develop/10tokens.asciidoc\nBRC20 # BRC20 是一位名为 @domo 的推特用户在 2023 年 3 月提出的协议，这个协议的思想来源于 ERC20，希望能在比特币链上创建可替代代币。但由于比特币并不支持智能合约，需要借助 ordinal 铭刻。\nOrdinal 协议 # 2023 年 1 月 21 日，Casey Rodarmo 推出了 Ordinal 协议，在比特币链上铸造 NFT 成为可能。此前比特币一直被认为除了“数字黄金”外没有太多其他作用。\n比特币总共 21,000,000 个，而比特币的最小单位是聪（Satoshi），1BTC = 100,000,000 Satoshi，所以全部的比特币的数量是2,100,000,000,000,000 Satoshi。Ordinal 通过为这些Satoshi进行顺序编号，将这些 Satoshi 区别开来，这也是“Ordinals：序数”这个项目名字的由来。编号的方式有多种，比如直接按照纯数字的顺序号比如[2099994106992659](https://ordinals.com/sat/2099994106992659)，或者按照每个Satoshi出现位置的区块号+偏移量比如[3891094.16797](https://ordinals.com/sat/3891094.16797) 等。\n这样编号之后，任意资产，如NFT、安全代币、账户或稳定币，可以使用序号作为稳定标识符附加到 satoshis 上，Ordinals 把这个“附加（attach）”动作成为铭刻（inscribe），类比以太坊NFT的铸造（mint）行为。\n为什么编号之后一个 Satoshi 就和其他的 Satoshi 不一样了呢？我们可以举一个生活中的例子。很多魔术师在表演的时候会用到硬币、纸牌等作为魔术道具，为了像观众证明魔术师自己没有偷换过硬币，没有在硬币上做手脚，魔术师会让观众当场在硬币上做个记号，并向观众暗示这个做完记号的硬币就是世界上独一无二的硬币，是和其他硬币不一样的，魔术师不可能用其他的硬币来偷换。所以 ordinal 序数理论的方式，就是通过在硬币上作记号来达到每一个 Satoshi 都和其他的不一样的效果。\nOrdinals 铭文（inscription）相比于以太坊等智能合约构建的NFT体系的另一个不同点是，Ordinals 铭文的所有数据都是存在链上的，不依赖于 IPFS 或是 AWS S3 等外部存储，是真正意义上去中心化的，和其他所有的比特币交易一样，在区块链中保存。\nOrdinal 编号规则 # Ordinal 协议给每个聪都分配了独一无二的编号，这个编号有若干种表示方法：\nInteger: 2099994106992659 ，根据每个聪被挖出的顺序依次编号。 Decimal: 3891094.16797，小数点前的数字是聪被挖出时的区块高度，小数点后的数字是聪在区块内的偏移。 Degree: 3°111094′214″16797‴， Percentile: 99.99971949060254% ，这是该聪在比特币供应量中的位置，用百分比表示。 Name: satoshi，是用字母 a 到 z 编码的序数号。 Ordinal 的官方文档对 Degree 表示法有详细的解释，它本质上是根据比特币自身的一些定期事件，人为赋予差别。比如比特币世界里，一些事件经常发生，一些较为罕见，这些事件自然而然地形成了一种稀有度系统。这些定期事件包括：\n区块（block）：大约每10分钟会挖出一个新区块，永远是这个数值。 难度调整（difficulty adjustments）：每 2016 个区块，即每两周，比特币网络会根据哈希率的变化调整难度目标。 减半（halvings）：每 210,000 个区块，即，每四年，每个区块挖到的奖励减半。 周期（cycles）：每隔 6 次减半，会发生一些神奇的事情：减半和难度调整同时发生。这被称为「重叠」，在两次重叠之间的时间段被称为一个「周期」。「重叠」大约每24年发生一次。第一次重叠应该在 2032 年左右发生。 这给我们带来了以下的稀有度级别：\n普通：不是其块的第一个聪 少见：每个块的第一个聪 稀有：每个难度调整周期的第一个聪 史诗：每个减半时期的第一个聪 传奇：每个周期的第一个聪 神话：创世区块的第一个聪 A°B′C″D‴ │ │ │ ╰─ Index of sat in the block │ │ ╰─── Index of block in difficulty adjustment period │ ╰───── Index of block in halving epoch ╰─────── Cycle, numbered starting from 0 本节参考资料：\nhttps://blog.chain.link/brc-20-token/#what_is_the_brc-20_token_standard_\nhttps://www.jinse.com/blockchain/3094348.html\nhttps://yishi.zhubai.love/posts/2249248982721544192\nhttps://docs.ordinals.com/overview.html\nOrdinal 怎么将铭文铭刻在比特币上？ # 在讨论铭刻之前，需要先了解下比特币扩容的两次重大升级：SegWit 和 Taproot。\nSegWit（隔离见证）\n他是比特币的一个重大升级于 2017 年 8 月激活，主要目的是优化比特币的交易处理能力、降低交易费用，并在更安全的条件下实现比特币的扩容。SegWit 是一个软分叉（Soft Fork）升级，涵盖多个 BIP（141、142、143、144 和 145），所谓软分叉也就是可以兼容老版本的比特币客户端，没有破坏比特币网络的兼容性。\n它的核心改变是把交易中的签名（Witness Data）从交易数据中分离出来，使交易数据更小，从而减少交易费用，并提高比特币网络的容量。\nSegWit 的实现方式是将所有的交易数据分为两部分，一部分是交易的基本信息（Transaction Data），另一部分是交易的签名信息（Witness Data），并把签名信息保存在一个新的数据结构中，是被称为“隔离见证（witness）”的新区块中，并与原始交易分开传输。这样，比特币交易的交易数据大小提高了上限，同时降低了签名数据的交易费用。在 SegWit 升级之前，比特币的容量上限是1MB，而 SegWit 之后，比特币交易的容量上限达到了4MB。\n所以 Oridnals Inscription 的本质就是把铭刻数据藏在见证数据中。\nTapRoot\n与 SegWit 升级类似，Taproot 升级同样是一种软分叉升级，是 Bitcoin Core 贡献者 Gregory Maxwell 在 2018 年提出的比特币升级提案，它并不会改变比特币协议本身，而是对现有的比特币交易机制进行改进。该升级主要包含 3 个技术概念 —— P2SH、MAST 和 Schnorr 。其结果是让复杂的交易如多签名交易、时间锁交易看起来如同普通的比特币交易，增强了比特币的隐私性，目的是推动了比特币实现智能合约部署、拓展用例等各种场景升级。在 SegWit 升级中，比特币协议增加了一个新的版本号，用于表示新的交易格式。在 Taproot 升级中，比特币协议最重要的更改是将脚本验证程序从 ScriptVerify flag 更新为 ScriptVerifyv2 flag，以支持 Tapscript。一个 Tapscript 的上链需要分为两个步骤：commit 和 reveal。而 Inscription（铭刻）的内容则包含在 reveal 交易的第一个输入中，从而铭刻在此交易的第一个输出的第一个 sat 上。比如：\nOP_FALSE OP_IF OP_PUSH \u0026#34;ord\u0026#34; OP_1 OP_PUSH \u0026#34;text/plain;charset=utf-8\u0026#34; OP_0 OP_PUSH \u0026#34;Hello, world!\u0026#34; OP_ENDIF 这里有多个操作指令，但是开头必然是 OP_FALSE，此指令被推入执行栈后脚本就会停止运行，但仍然被存在了链上。\n所以 Ordinal Inscription 的本质是：在比特币网络上借助一个永远不会被执行的脚本 tapscript，搭建了一个简易的记账层 ，进行资产和数据的统计和记录。\n由于只有记账，这就意味着不会有类似智能合约的脚本执行以及验证的过程，必然高度依赖链下的中心化管理和上报结果。\n本节摘录自：https://news.marsbit.co/20230522142055973596.html\nBRC20 # 学习了 Ordinal 协议相关内容后，是时候了解一下 BRC20 的思想了。实际实现中，BRC20 是通过 Ordinal 铭文实现的。我一直很困惑，如果想要在比特币上实现 fungible token，似乎没必要借助 ordinal 协议吧？但 domo 本人写的文档里提到这个实验性标准本来就是为了看看序数理论能不能促进比特币 fungibility 的发展，所以就不用纠结到底是不是一定需要 ordinal 协议的事情了。\nBRC20 是通过将一定格式的 JSON 文本铭刻到 bitcoin 上，来实现发行、铸造和交易代币的逻辑。\n三种操作 # 部署 BRC20 代币\n{ \u0026#34;p\u0026#34;: \u0026#34;brc-20\u0026#34;,//Protocol: 帮助线下的记账系统识别和处理brc-20事件 \u0026#34;op\u0026#34;: \u0026#34;deploy\u0026#34;,//op 操作: 事件类型 (Deploy, Mint, Transfer) \u0026#34;tick\u0026#34;: \u0026#34;ordi\u0026#34;, //Ticker: brc-20代币的标识符，长度为4个字母（可以是emoji） \u0026#34;max\u0026#34;: \u0026#34;21000000\u0026#34;,//Max supply: brc-20代币的最大供应量 \u0026#34;lim\u0026#34;: \u0026#34;1000\u0026#34;//Mint limit: 每次brc-20代币铸造量的限制 } 这里给出各个参数的要求和描述。\nKey Required? Description p Yes Protocol: Helps other systems identify and process brc-20 events op Yes Operation: Type of event (Deploy, Mint, Transfer) tick Yes Ticker: 4 letter identifier of the brc-20（BRC20 代币的名称，不区分大小写，不可和已有的重复） max Yes Max supply: set max supply of the brc-20（该代币的最大发行量） lim No Mint limit: If letting users mint to themsleves, limit per ordinal dec No Decimals: set decimal precision, default to 18 铸造 BRC20 代币\n{ \u0026#34;p\u0026#34;: \u0026#34;brc-20\u0026#34;, \u0026#34;op\u0026#34;: \u0026#34;mint\u0026#34;, \u0026#34;tick\u0026#34;: \u0026#34;ordi\u0026#34;, \u0026#34;amt\u0026#34;: \u0026#34;1000\u0026#34; } Key Required? Description p Yes Protocol: Helps other systems identify and process brc-20 events op Yes Operation: Type of event (Deploy, Mint, Transfer) tick Yes Ticker: 4 letter identifier of the brc-20 amt Yes Amount to mint: States the amount of the brc-20 to mint. Has to be less than \u0026ldquo;lim\u0026rdquo; above if stated 转移 BRC20 代币\n{ \u0026#34;p\u0026#34;: \u0026#34;brc-20\u0026#34;, \u0026#34;op\u0026#34;: \u0026#34;transfer\u0026#34;, \u0026#34;tick\u0026#34;: \u0026#34;ordi\u0026#34;, \u0026#34;amt\u0026#34;: \u0026#34;100\u0026#34; } Key Required? Description p Yes Protocol: Helps other systems identify and process brc-20 events op Yes Operation: Type of event (Deploy, Mint, Transfer) tick Yes Ticker: 4 letter identifier of the brc-20 amt Yes Amount to transfer: States the amount of the brc-20 to transfer. to No Address to send to: States the receiving address. If left blank logic will presume that the receiver of the transfer is correct. fee No Transfer fee: For tracking without taproot data purposes only 但要注意，这些 JSON 代表的逻辑并不由比特币的全节点执行，用户必须完全信任链下负责解释铭文的索引器。\n本节参考资料：\nhttps://domo-2.gitbook.io/brc-20-experiment/\n"},{"id":8,"href":"/post/2023-04-30-SSH-Agent-Forward-%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","title":"OpenSSH Agent Forward 失败解决方法","section":"Posts","content":"因为我的笔记本电脑是 Windows 系统，在很多场景下不方便环境配置，因此经常在 Linux 服务器上进行 GitHub 项目的开发。为了在服务器上更方便地连接到 GitHub 的服务器，我在使用 ssh 连接服务器时默认开启了 ForwardAgent 选项。\n但最近一个多月以来，我发现在本机 ssh-agent 添加了本地私钥并正常运行、且本机可以 ssh 连接到 GitHub 服务器（命令 ssh -T git@github.com）的情况下，通过 ssh 远程连接到 Ubuntu 20.04/22.04 Server 后，Ubuntu Server 无法 ssh 连接到 GitHub 服务器。\n通过一系列探索和尝试，最终解决了该问题，特记录之。\nssh agent 原理 # 参考：\nhttps://smallstep.com/blog/ssh-agent-explained/\nhttps://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html\n上面描述的是问题现象，解决问题前需要大致了解 SSH Agent 的工作原理。\n什么是 ssh agent # ssh agent 是一个保存用于公钥认证（RSA, DSA）的私钥的程序。它将用户的私钥和证书保存在内存中，供 ssh 使用。ssh agent 和 ssh 是两个不同的程序，它们分别运行，并且 ssh agent 一般在登陆会话开始时启动。\nssh agent 通过下面的方式确保用户私钥安全：\n不会将私钥写入硬盘 不允许将用户的私钥被导出 另外，私钥只是用来进行 authentication 的，并不是用来对发送和接收的消息做加解密的。\n若是口令登录，经历了以下几个步骤：\n远程主机收到用户的登录请求，把自己的公钥发给用户 用户使用这个公钥，将登录密码加密后，发送回来 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录 若是公钥登录，即用户已经将自己的公钥存储在远程主机的 $HOME/.ssh/authorized_keys 文件中，则：\n远程主机向用户发送一段随机字符串 用户用自己的私钥加密后将加密后的消息发送给服务器 远程主机用事先存储的公钥进行解密，如果成功，证明用户可信 注意，如果想要本地的公私钥更加安全，可以在 ssh-keygen 时设置 passphrase 对私钥进行加密。\nThe agent protocol # agent protocol 比较简单，它进行了以下操作：\n增加密码对 ssh-add When run without arguments, it adds the files ~/.ssh/id_rsa, ~/.ssh/id_ecdsa, ~/.ssh/id_ecdsa_sk, ~/.ssh/id_ed25519, ~/.ssh/id_ed25519_sk, and ~/.ssh/id_dsa. 移除密码对 ssh-add -d 列出存储在 agent 中的所有密码对 ssh-add -l or ssh-add -L 用存储在 agent 中的私钥对消息进行签名 锁住/解锁 agent 锁住：ssh-add -x 解锁：ssh-add -X agent forwarding 原理 # 试想一个场景：我的笔记本通过 ssh 连接到了实验室的服务器，在实验室的服务器上，我希望通过 git 克隆一个仓库。如果没用 agent forwarding，那么我需要将这台服务器的 public key 添加到 GitHub 账号。如果用了 agent forwarding，那么服务器可以通过我的笔记本的 private key 连接到 GitHub 服务器。\nagent forwarding 运行原理 # ssh 连接可以有多个 channel。比如 interactive shell 的连接建立在一个 channel 上，agent forwarding 建立在另一个 channel 上，通过这个 channel，远程主机可以将 agent 的请求转发到本地机器。\n图片来源于：https://smallstep.com/blog/ssh-agent-explained/\nagent forward 的安全风险 # 远程主机上任何有 root 权限的人可以通过这个 Unix socket 访问本地机器的 ssh agent，因此攻击者可以从本地机器的 ssh agent 拿到签名过的消息，从而伪装成用户。注意通过本地的 ssh agent 拿不到私钥内容。\n一些让 agent forwarding 更安全的方法 # 不要默认打开 ForwardAgent\n比如：\nHost example.com ForwardAgent yes 在需要进行 agent forwarding 时，使用 ssh -A 对单次登录开启 agent forwarding\n当使用 agent forwarding 时，锁住本机的 ssh agent（ssh-add -x 用密码锁住 ssh agent）。当你连接到远程主机时，如果攻击者没有这个密码，便无法访问你的 ssh agent。\n使用更安全的 ssh agent 实现。如 Sekey 和 Secretive。\n不使用 agent forwarding，使用 ProxyJump\n问题排除 # 检查本地 ssh-agent 是否运行\nWindows 系统中，“我的电脑”右键选择“管理”，在管理界面中选择“服务和应用程序”-\u0026gt;“服务”，在右侧的列表中选择 OpenSSH Authentication Agent，双击查看属性。\n检查本地 ssh-agent 是否添加了正确的私钥\n通过 ssh-add -l 命令可以查看到添加了正确的私钥。\n检查服务器 ssh-agent 是否运行\n~\u0026gt; echo \u0026#34;$SSH_AUTH_SOCK\u0026#34; /tmp/ssh-XXXXyV8l5r/agent.1765943 可知服务器的 ssh-agent 正在运行。\n检查服务器的 sshd 配置文件是否允许 agent fowarding（默认开启）\n可以看到已经开启。\nssh -T git@github.com -vvv 查看详细信息\n发现有这么一行：\nchannel 1: chan_shutdown_read: shutdown() failed for fd 7 [i0 o0]: Not a socket 可以确定不是合法的 socket，由于没有找到 socket，服务器遍历了所有自己的私钥，都失败了。最终连接失败。\n描述了自己看到的问题，看到了一个答案：\nhttps://serverfault.com/questions/1113797/ssh-agent-forwarding-not-working-on-ubuntu-22-04\n这个答案提出 Windows 的旧版本 OpenSSH 和 Ubuntu 22.04 上的 OpenSSH 存在兼容性问题（经过测试，Ubuntu 20.04 也存在兼容问题）。于是我按照答案所述，下载了 8.9.0p1Beta 版本的 Windows OpenSSH，并且更新了电脑的环境变量。ssh -V 命令显示的版本是刚刚下载的最新版本，但上述问题依旧存在。\n这时我又找到了一篇博客：\nhttp://blog.zencoffee.org/2022/11/openssh-on-windows-11/\n作者遇到了和我一样的问题。虽然运行的是新版本的 OpenSSH，但可能旧的环境没有清理干净。（比如 sshd 从来没停过）\n因此首先管理员权限打开 PowerShell，运行 OpenSSH-Win64 下的 uninstall-sshd.ps1，显示卸载成功后，将旧版 OpenSSH 的文件夹删除（可能需要修改文件夹权限）。再在 PowerShell 里运行 install-sshd.ps1，重新安装后添加 OpenSSH-Win64 路径到环境变量中，并启动 ssh-agent。\n重新 ssh 连接到服务器，测试 agent forwarding 结果。\n~\u0026gt; ssh -T git@github.com -vvv ...... ...... debug1: Will attempt key: C:\\\\Users\\\\{Username}/.ssh/id_rsa RSA SHA256:{SHA256 of private key} agent debug1: Will attempt key: hexy.pem RSA SHA256:{SHA256 of private key} agent debug1: Will attempt key: /home/{Username}/.ssh/id_rsa RSA SHA256:{SHA256 of private key} debug1: Will attempt key: /home/{Username}/.ssh/id_ecdsa debug1: Will attempt key: /home/{Username}/.ssh/id_ecdsa_sk debug1: Will attempt key: /home/{Username}/.ssh/id_ed25519 debug1: Will attempt key: /home/{Username}/.ssh/id_ed25519_sk debug1: Will attempt key: /home/{Username}/.ssh/id_xmss debug1: Will attempt key: /home/{Username}/.ssh/id_dsa ...... ...... ~\u0026gt; ssh -T git@github.com Hi elenacliu! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. "},{"id":9,"href":"/post/2022-12-31-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","title":"2022年终总结","section":"Posts","content":"转眼间就到了 2022 年的最后一天了。这一年我进行了很多尝试，有了新的收获和思考。仅从我个人的角度来说，2022 年是完满的一年，年初的一些大致规划都实现了。但 2022 年也有很多遗憾，来者犹可追。\n时间线 # 2022.1~2022.5\n顺利完成了毕设，第一次感受到了什么是稳扎稳打、循序渐进的科研。 学习了现代西班牙语1，很喜欢 Estrella 老师，亲切随和。课堂发言时总担心出错，她开导我学习语言的目的就是为了交流，会说二外是一件很酷的事情。确实很酷，尤其是世界杯的时候能大概看懂梅西讲话字幕 : ) 学习了经济学原理，第一次从计算机以外的视角看待世界。人性很奇妙。 周日上午在音乐图书馆学习吉他。主要学习和弦和节奏。 最后一门专业限选课：网络原理专题训练。“出来混总是要还的“。 鸿雁训练营的伦巴课：上了4节课，后来因为疫情没法上了。拉丁舞的舞步是基本功，要扭出味道很难。 学生节转到春季学期进行，成为了学生节志愿者。办好一次学生节真的不容易。所有人都辛苦了！ 2022.5~2022.6\n北京疫情开始严重，每天在寝室上课、学习。 周日的吉他课被迫转到线上，节奏部分耽误了。 2022.6\n毕业季。和亲朋好友在校园里拍了美美的照片，离别的时候看着空空的床铺，很难过。毕业典礼那天太热了，我选择了延期参加，希望明年还能有机会趁着毕业典礼的机会回来看看。 为系毕联活动尽了自己的一份力。我会永远记得这个夏天。 几乎是压着 ddl 申请了中科院开源之夏（ospp）项目，为 Jina AI 社区集成主流的 3D 点云分类网络。成功中选。 给 nsd 提交了校外经济学辅修的修读申请。 2022.7~2022.8\n远程科研，继续自己的毕设研究。 完成开源之夏项目。 陪伴家人，买菜做饭，学习钢琴，复习吉他。 7月底和高中同学一起去贵州毕业旅行，累并快乐着。贵阳真的好凉快，物价超值！ 入选研究生新生领航计划。 nsd 校外经济学辅修项目免试录取。 2022.9\n家乡疫情开始严重，趁着没有波及到所在地时提前返校。离开家人有些不舍。\n研究生开学，导师双选。没什么波澜。\n通过了开学的编程能力测试，不用修C/Java语言课了。开心。\n赶 ICLR deadline，每天奔波约 40 km，很累，但很有希望。\n入选了爱心社项目组。参加每周例会。\n开源之夏项目收尾工作。\n9 月是北京最美最舒适的日子，那段时间几乎每天穿过丰台往返于大兴和海淀之间，看遍了北京的秋高气爽。也明白了每个北漂的辛苦和不易。\n2022.10~2022.11 全年最忙碌的一个半月，忙到爆炸\n尝试了新发型。\n国庆之后开始赶 CVPR deadline。简单一行字，实际上几座大山压得人喘不过气。\n开源之夏项目终审通过。\n上课，作业，pre。主动挑大梁。\n2022.11\nPKUGeekGame v2：历时整整一周，第一次打 CTF。不知道那周怎么过来的，只要睁眼就在解题。不过，体验一次做 hacker 的感觉就好，因为实在是占用休息时间。好在有个不错的结果。 毕设科研项目收尾。 CVPR deadline 结束。 收到了开源社区的实习邀请，但考虑到时间因素还是婉拒了。 北京疫情又开始严重，学校开始封校。 2022.12\n实习离职。 开始准备各个期末大作业，以及考试。 没能挺进新冠决赛圈，休养了半个多月。 学校彻底解封。希望明年能带家人入校看看。 关键词 # 今年主动尝试了很多事，也被动接受了很多事。2022 年的生活让我感触颇多：\n及时沟通。无论是意见相左还是出现错误时，都需要及时、真诚沟通。沟通比藏着掖着更有效。 果断舍弃。有选择的情况下，果断舍弃你不想要的东西，以免产生长期内耗。 宽容平和。对自己多说：我允许。允许自己和他人犯错，知错能改，善莫大焉。 保持健康。新冠的侵袭让大家意识到，只有自己的免疫力强，才是最强大的。 最后也是最重要的：多陪伴家人。 展望 # 明年的努力目标：\n找到明确的发展方向。 拿到想要的证。 多为开源社区提交贡献。 继续进行自我修炼和探索。 最后也是最重要的：不在家时，每天和父母视频一次，让他们感受到我的关心；每年除了寒暑假以外，要么抽空回家，要么带家人出去玩。 "},{"id":10,"href":"/post/2022-07-03-adb%E7%AC%94%E8%AE%B0/","title":"adb 笔记","section":"Posts","content":"This is my first post written in English, because I think in such way it will be easier for foreigners to read my technical blogs.\nLately I tried to use Tasker, an application on Android, to do some timed tasks. You can write \u0026ldquo;ADB Wifi\u0026rdquo; codes in Tasker. However, what is ADB? How does it work to communicate between host and target device?\nReferences:\n[1] Android Debug Bridge: https://developer.android.com/studio/command-line/adb\n[2] ADB (Android Debug Bridge): How it works? https://events.static.linuxfound.org/images/stories/pdf/lf_abs12_kobayashi.pdf\n[3] ADB工具原理探究: https://itimetraveler.github.io/2019/06/07/Android%20ADB%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/#%E8%80%8C-emulator-device-%E8%B0%83%E7%94%A8adbd\n[4] 用了 adb 这么久，看了这篇才明白: https://ld246.com/article/1578276924255\nBasic Concepts # Android Debugger Bridge (adb) is a versatile command-line tool that lets you communicate with a device. The adb command facilitates a variety of device actions, such as installing and debugging apps, and it provides access to a Unix shell that you can use to run a variety of commands on a device.\nHere device means target devices (usually Android phones or emulators).\nIt is a client-server program that includes three components:\nA client, which sends commands. The client runs on your development machine. (Here development machine means your PC which develops Android Apps) You can invoke a client from a command-line terminal by issuing an adb command. A daemon (adbd), which runs commands on a device. The daemon runs as a background process on each device. A server, which manages communication between the client and the daemon. The server runs as a background process on your development machine. How to Connect # As you can see in the picture, adb shell runs as a client in our PC and sends commands to emulator or Android phones. How can the adbd daemon process communicate with adb client running in host machine?\nThe answer is illustrated in the figure below. Adb server acts as proxy between adb clients and adbd. Adb server connects with adb clients and adbd on the same machine through TCP, while with those on another machine through TCP or USB connection.\nNow it\u0026rsquo;s time for digging into the connecting process.\nWhen you start an adb client, the client first checks whether there is an adb server process already running. If there isn\u0026rsquo;t, it starts the server process. When the server starts, it binds to local TCP port 5037 and listens for commands sent from adb clients. All adb clients use port 5037 to communicate with the adb server.\nThe server then sets up connections to all running devices (here it means all running target devices). It locates emulators by scanning odd-numbered ports in the range 5555 to 5585, the range used by the first 16 emulators. Where the server finds an adb daemon, it sets up a connection to that port. Note that each emulator uses a pair of sequential ports - an even-numbered port for console connections and an odd-numbered port for adb connections. For example:\nEmulator 1, console: 5554\nEmulator 1, adb: 5555\nEmulator2, console: 5556\nEmulator2, adb: 5557\nand so on\u0026hellip;\nAs shown, the emulator connected to adb on port 5555 is the same as the emulator whose console listens on port 5554.\nIn my perspective, console connection is only applicable to emulator instances:\nEach running virtual device provides a console that lets you query and control the emulated device environment.\nNow let\u0026rsquo;s analyze what happens indeed when typing adb devices or other adb commands in command line.\nTo be continued\nRoles of adb # Transport: communication path between host and target device USB or TCP: but clients don\u0026rsquo;t have to be aware Services: executing something on the target devices through the transport adb shell for executing command adb push/pull for file transfer How to start adb server # With adb start-server you can explicitly start adb server as background process. However you do not have to do that, because after adb devices adb server will be initialized automatically.\nList of devices attached * daemon not running. starting it now at tcp:5037 * * daemon started successfully * When you want to restart adb server, run adb kill-server.\nActually, adb clients and adb server shares same executable. So adb start-server equals adb fork-server server\u0026amp;\nWorking Sequence # Source Code Analysis # The source code is located in the directory system/core/adb. The executables, adb and adbd, are both compiled from it. You can control the compilation process by setting ADB_HOST.\n#if ADB_HOST /* code for adb */ #else /* code for adbd */ #endif Secure Mode # Android phones have adbd running on secure mode (secure == 1)\nIf secure == 1, change adbd as shell user(=not privileged user), else it runs as root user.\nIn secure mode, all services invoked by adbd run as shell user. So some services causes \u0026ldquo;permission denied\u0026rdquo;.\nIf the device is an emulator, then secure == 0.\nConnect to a device over Wi-Fi # Android 10 and lower # adb usually communicates with the device over USB, but you can also use adb over Wi-Fi. To connect a device running Android 10 or lower, there are some initial steps you must do over USB, as described below:\nConnect your Android device and adb host computer to a common Wi-Fi network accessible to both. Beware that not all access points are suitable; you might need to use an access point whose firewall is configured properly to support adb.\nIf you are connecting to a Wear OS device, turn off Bluetooth on the phone that\u0026rsquo;s paired with the device.\nConnect the device to the host computer with a USB cable.\nSet the target device to listen for a TCP/IP connection on port 5555.\n\u0026gt; adb tcpip 5555 Disconnect the USB cable from the target device. Find the IP address of the Android device. For example, on a Nexus device, you can find the IP address at Settings \u0026gt; About tablet (or About phone) \u0026gt; Status \u0026gt; IP address. Or, on a Wear OS device, you can find the IP address at Settings \u0026gt; Wi-Fi Settings \u0026gt; Advanced \u0026gt; IP address. Connect to the device by its IP address. Confirm that your host computer is connected to the target device: \u0026gt; adb devices List of devices attached device_ip_address:5555 device Android 11+ # to be continued\nCommunication Protocol # "},{"id":11,"href":"/post/2022-07-02-Tasker%E7%AC%94%E8%AE%B0/","title":"Tasker 笔记","section":"Posts","content":" Tasker # 简介 # Tasker 是一款在安卓手机上实现定时任务的付费应用，官方提供 7 天的免费试用期。其功能非常强大，能够在无 root 权限下完成对手机的各种模拟操作。当然，和 Tasker 搭配的插件很多是需要 root 权限才可以完成工作的。\n笔者使用的是 HarmonyOS，但没找到 root 的方法，所以网友提出的很多操作方法没法实践。\n安装和使用 # 安装链接：点击这里\n该应用的 UI 十分简陋，这里记录一些基本使用步骤。\n任务 点击右下角加号可以进入创建任务的界面\n进入创建任务的界面，可以选择定义任务的方式\n比较常用的有代码、任务和插件。\n其中代码可以选择 adb wifi, Java function, Java object, Javascript, Javascriptlet, shell 脚本等等。\n任务有等待、执行任务（一般是你定义好的其他任务）。\n插件则可以调用其他 Tasker 支持的应用，比如 SecureSettings，AutoInput…… 这些插件可以加强 Tasker 执行任务的功能。插件的具体功能在对应部分讲解。\n配置文件 点击右下角加号可以添加配置文件\n配置一般是触发任务的条件。因此在添加配置的时候，需要指定事件、位置、或者时间等条件。\nADB # 简介 # 相信曾经使用过 Android Studio 开发安卓应用的人都听说过这个玩意，全称 Android Debug Bridge。虽然官方网页上对 ADB 的原理介绍非常简略，但这个通信过程好像并不简单。打算未来再开篇文章研究下。\n从功能来说，感觉 ADB 其实就是提供了用其他设备（可能是 PC）调试安卓设备的方法。无论是 emulator 还是 shell，都是很方便的。\n使用 # 目前只使用了 adb shell 的方法，用命令行进行调试。另，笔者 PC 端的操作系统是 Windows10。\ninput # adb shell input [keyevent/keyboard/swipe/tap] 命令可以模拟输入。\nkeyevent 主要用来模拟特殊按键的点击。\nadb shell input keyevent 3 # 按 home 键 adb shell input keyevent 26 # 按电源键 其他的 KEYCODE 列表：\nKEYCODE_UNKNOWN=0; KEYCODE_SOFT_LEFT=1; KEYCODE_SOFT_RIGHT=2; KEYCODE_HOME=3; //home键 KEYCODE_BACK=4; //back键 KEYCODE_CALL=5; KEYCODE_ENDCALL=6; KEYCODE_0=7; KEYCODE_1=8; KEYCODE_2=9; KEYCODE_3=10; KEYCODE_4=11; KEYCODE_5=12; KEYCODE_6=13; KEYCODE_7=14; KEYCODE_8=15; KEYCODE_9=16; KEYCODE_STAR=17; KEYCODE_POUND=18; KEYCODE_DPAD_UP=19; KEYCODE_DPAD_DOWN=20; KEYCODE_DPAD_LEFT=21; KEYCODE_DPAD_RIGHT=22; KEYCODE_DPAD_CENTER=23; KEYCODE_VOLUME_UP=24; KEYCODE_VOLUME_DOWN=25; KEYCODE_POWER=26; KEYCODE_CAMERA=27; KEYCODE_CLEAR=28; KEYCODE_A=29; KEYCODE_B=30; KEYCODE_C=31; KEYCODE_D=32; KEYCODE_E=33; KEYCODE_F=34; KEYCODE_G=35; KEYCODE_H=36; KEYCODE_I=37; KEYCODE_J=38; KEYCODE_K=39; KEYCODE_L=40; KEYCODE_M=41; KEYCODE_N=42; KEYCODE_O=43; KEYCODE_P=44; KEYCODE_Q=45; KEYCODE_R=46; KEYCODE_S=47; KEYCODE_T=48; KEYCODE_U=49; KEYCODE_V=50; KEYCODE_W=51; KEYCODE_X=52; KEYCODE_Y=53; KEYCODE_Z=54; KEYCODE_COMMA=55; KEYCODE_PERIOD=56; KEYCODE_ALT_LEFT=57; KEYCODE_ALT_RIGHT=58; KEYCODE_SHIFT_LEFT=59; KEYCODE_SHIFT_RIGHT=60; KEYCODE_TAB=61; KEYCODE_SPACE=62; KEYCODE_SYM=63; KEYCODE_EXPLORER=64; KEYCODE_ENVELOPE=65; KEYCODE_ENTER=66; KEYCODE_DEL=67; KEYCODE_GRAVE=68; KEYCODE_MINUS=69; KEYCODE_EQUALS=70; KEYCODE_LEFT_BRACKET=71; KEYCODE_RIGHT_BRACKET=72; KEYCODE_BACKSLASH=73; KEYCODE_SEMICOLON=74; KEYCODE_APOSTROPHE=75; KEYCODE_SLASH=76; KEYCODE_AT=77; KEYCODE_NUM=78; KEYCODE_HEADSETHOOK=79; KEYCODE_FOCUS=80;//*Camera*focus KEYCODE_PLUS=81; KEYCODE_MENU=82; KEYCODE_NOTIFICATION=83; KEYCODE_SEARCH=84; KEYCODE_MEDIA_PLAY_PAUSE=85; KEYCODE_MEDIA_STOP=86; KEYCODE_MEDIA_NEXT=87; KEYCODE_MEDIA_PREVIOUS=88; KEYCODE_MEDIA_REWIND=89; KEYCODE_MEDIA_FAST_FORWARD=90; KEYCODE_MUTE=91; keyboard text 用于模拟键盘输入。\nadb shell input keyboard text \u0026#34;the first msg via adb\u0026#34; tap 用于模拟点击。\nadb shell input tap x y # x, y 坐标可以通过开启开发人员选项后显示指针位置和坐标来获取 swipe 用于模拟触摸滑动。\nadb shell input swipe x1 y1 x2 y2 # x1, y1 是起始点，x2, y2 是终点。轨迹是直线，不能实现多点连续滑动（具体实现方法见后文对应部分） 遇到的问题 # adb 是未识别的命令，本质上是环境变量的问题，但后来发现我压根不记得电脑上的 adb.exe 在哪里了。\n下载链接指路：\nadb 包含在 Android SDK 平台工具软件包中。您可以使用 SDK 管理器下载此软件包，该管理器会将其安装在 android_sdk/platform-tools/ 下。或者，如果您需要独立的 Android SDK 平台工具软件包，也可以点击此处进行下载。\n使用 USB 线连接上手机后，使用 adb devices 发现输出一直是 unauthorized。这种情况重新插拔、允许 USB 调试、选择传输文件后、运行了 adb kill-server 就能够识别了。怀疑是线插好得太早，彼时 adb 命令什么的还没弄好导致的。\nTasker 常用插件 # SecureSettings # SecureSettings 能够在没有 root 权限的情况下做到 Wake Device，这对于需要在手机熄屏后依然能够定时执行的任务很重要。但这款应用也有很多功能需要 root 权限。\n相关链接 # 这里 列出了 Tasker 玩家经常入手的一些小插件。作者列出了功能和是否免费的相关信息。\n为了防止 原文 哪天 404 了，我将这部分内容摘抄如下（如有侵权，请及时联系笔者删除）：\nAutoTools:\n☑安全设置 切换位置，夜间模式，省电模式和其他以前无法访问的设置\n☑对话框对话框可以读取指纹，询问您的问题，显示图像，让您选择文件和日期以及更多内容，从而使您的任务变得互动且美观。\n☑Web屏幕 重新想象创建UI Tasker的工作方式：从许多预设之一导入，对其进行配置，您就完成了！在此处查看所有可用的Web屏幕：https://joaoapps.com/autotools/web-screen-presets/\n☑轻松进行数据处理 轻松读取和写入JSON数据，读取网站（HTML）数据，读取XML数据，操作同时使用多个Tasker数组，使用强大的Regex工具轻松地从任何文本获取信息，并以前所未有的方式处理文本！\n☑完全可定制的Toast提示 展示前所未有的Toast提示。设置自定义字体，颜色和布局！\n☑Android7应用程序快捷方式 有动态创建的时长，点击自动工具主屏幕上的快捷方式图标\n☑徽章 阅读和支持的发射器设置的其他应用程序的数字的徽章\n☑OCR 从图像识别文本和塔斯克但使用它你喜欢\n☑手势屏 屏幕，支持多类型的手势和支持压力感应的命令！（如3D触摸）\n☑时间计算可以轻松以任何方式计算时间差或格式化时间！\n☑Chrome自定义标签页 使用所需的颜色，按钮和操作创建自己的Chrome标签页！\n☑壁纸直接通过URL设置您的主屏幕和锁屏壁纸\n☑闪光灯轻松使闪光灯呈图案闪烁\nAutoNotification:\n独立功能：\n☑阻止任何应用程序通知的出现对于持续性通知，需要Android 8+。对于常规通知，需要Android 4.4+。视频教程在这里。\n☑管理通知类别对于不是为Android Oreo或更高版本构建的应用程序，您可以更改比常规系统选项更多的设置，例如重要性，声音，振动等。对于为Oreo或更高版本构建的应用程序，您可以设置振动模式，通常是无法做到的！此处的视频教程：https://youtu.be/AcTVnop3M3s☑自定义Gmail通知按钮设置所需的Gmail通知按钮！从14个不同的按钮中进行选择（包括标记为已读，删除等）以及最多5个！此处的视频演示：https://youtu.be/dovLa8mMvpI 注意：当您在其他设备上阅读电子邮件时，自动通知无法检测到，因此它不会像本机Gmail应用程序那样自动删除其Gmail通知。\nTasker插件功能：\n☑使用高级格式创建很棒的交互式通知：在此处查看教程。\n☑快速设置图块最多可添加40个Android 7+快速设置图块，以自定义您的内心需求！\n☑表格通知在通知阴影中创建一个包含图像的表。此处的教程\n☑按钮通知可以根据需要发送任意数量的按钮通知！是的，如果您愿意，可以有50个按钮！:)\n☑拦截和查询通知在Tasker中对其他应用程序的通知做出反应，并用它们做任何您想做的事，包括将其替换为您自己的更好版本：)\n☑自动回复创建聊天机器人并自动回复聊天应用程序通知，如Whatsapp，环聊等\n☑Android 8+功能！管理第三方应用程序的通知类别并暂停通知\nAutoInput:\n独立功能:\n☑人脸解锁在任何Android设备7+ 你可以只用你的脸自动解锁你的锁屏！Tasker不是必需的！此处的完整教程：https://goo.gl/CipdM7\nTasker功能：\n☑适用于Android 4.3+的无root UI自动化 您可以在任何应用程序中模拟触摸和其他UI交互，例如输入文本，而无需root！在此处查看演示视频：https://www.youtube.com/watch?v=U6ajlDn3cwY例如： →从Tasker中随意更改任何应用程序的设置！ →无需触摸手机即可回复视频群聊！ →无需root就可以在手机上切换GPS！\n☑获取在任何屏幕上的文本 您可以在“任务”中使用读取屏幕上的信息！例如，使用Google Now识别一首歌曲，并在任务获取它的名字，在本教程：https://goo.gl/cWtiqq\n☑反馈屏幕活动 可以在Tasker设置配置文件当屏幕上的内容改变时触发，例如单击按钮或更改其内容的应用程序\n☑自动化任何应用程序 从现在开始，当您问自己“我可以使用Tasker自动操作该应用程序吗？”，答案是“您也许可以使用AutoInput进行操作”！:)\nAutoShare:\nTasker添加支持Tasker与任何应用程序！ HTTP://goo.gl/r1ibqy 在日益扩大的应用数量与可在这里AutoShare意图做任何事情。您也可以从常规的Android菜单分享AutoShare和获得信息。 使用Android的分享菜单，即从分享的文本或文件中的列表和选项中选择AutoShare！与AutoShare相关的几个变量： – ％assender（包含发送应用程序的包名;分享给AutoShare的应用程序） – ％assubject（包含分享的主题） – ％astext（包含分享文本） – ％asfile1，％asfile2，％asfile3等（包含分享文件的路径;可在Tasker被作为一个数组访问名为％asfile）有了AutoShare功能命令，你可以很容易地了解Tasker分享的内容能做什么。例如，在一个配置文件，并在相应的任务使用“复制”命令，％astext复制到剪贴板。然后用命令AutoShare分享，然后从下拉列表中选择“复制”，不管你分享将可以在您的设备的剪贴板您也可以从内部Tasker创建Android分享菜单中的AutoShare与您所选择的主题，文本和图像。- 拦截分享到其他应用，你可以调整它们或使用Tasker变量来使处理的intent参数..观看此视频复制他们完全理解：http://youtu.be/4QPi56Brqsg例如使用（所有这些命令都是自由的形式，你可以自由地使用喜欢的任何命令）： – 分享到剪贴板：分享能够文本复制到手机的剪贴板 – 分享同时多个社交网络：分享到AutoShare“社交”命令，在弹出Tasker一个窗口，输入您的个人评论，然后用AutoRemote（http://goo.gl/uJSce）发送到Zapier这又瞬间张贴在Facebook，Twitter等！ 🙂 – URL添加到您的阅读在家列表：分享网址，使用“readathome”命令，打开当你回家你的手机上，甚至您的计算机AutoRemote这些URL（http://goo.gl/uJSce） – 在分享到其他服务之前以你喜欢的任何方式改变文本：使用“修改”命令分享任何东西，修改文本，或改变它在你喜欢的任何方式，并通过AutoShare另一个应用程序转贴 – 添加分享发送和接收能力到独立应用程序 – 将项目添加到您的待办事项列表：以“待办事项”命令分享任何文本，并将其添加到Tasker列表 – 到家里时分享：当你回家记得分享特殊照片么？只需设置连接到AutoShare任务上Wi-Fi连接配置文件，当你回家，你会被提醒即时分享照片\nAutoVoice:\n☑将自定义语音命令添加到Google Now / Assistant / Google Home和Amazon Echo https://youtu.be/q21X3wVAXI8\n☑自然语言 自然地说！您无需记住设置的确切命令：https://youtu.be/SboXku53g9o\n☑在Mac，Windows，Linux PC或其他Android设备上说出语音命令 在此处查看：https://www.youtube.com/watch?v=5vxslPnywus\n☑不到1分钟的时间即可设置酷炫的新语音命令 创建新的Tasker配置文件-\u0026gt;设置命令过滤器-\u0026gt;创建任务- \u0026gt;完成！\n☑蓝牙耳机兼容性 适用于大多数蓝牙耳机！\n☑从 Tasker 设置中识别 带有多个语音命令的复杂的任务，或者在特定情况下开始识别。您的极限就是您的想象力！\n☑超级灵活的设置可实现超级强大的配置文件 使用了许多自定义变量，对语音命令的反应从未如此轻松！http://joaoapps.com/autovoice/variables/\n☑将所有电话音频重定向到蓝牙耳机 是的，手机上的所有声音都可以放在非A2DP蓝牙小耳机上！\n☑对Tasker中的蓝牙耳机按钮 做出反应使用耳机上的常规呼叫按钮可以在Tasker中进行操作！可能不适用于所有型号的耳机\n☑对您周围的环境噪音做出反应 创建一个婴儿监护仪或一个拍板。噪音从未如此有趣！\nIntentTask:\nIntent（意图）是安卓应用之间的通信的方式: 1) 可以快速方便的添加意图，并且可以有更多的自定义. 可以接收发送意图的返回结果. 2) 可以使用Tasker变量运行程序 3) 可以使用快捷方式 4)可以创建文本处理器来处理文本内容 (Android 6+) .5) 可以为分享操作添加自定义的命令 6) 维持前置应用而不需要无障碍服务 (Android 5.1+)。（注：站长最喜欢的插件）\nTouchTask:\n监听和管理系统手势操作而不需要root 1. 操作: – 行为: 点击, 长按, 滚动, 剪切, 复制, 粘贴,输入文本, 选择文本 – 手势: 划屏 和 固定屏幕 (要求 Android 7+) – 截屏类: 截屏和录屏, 图片压缩, 获取图片颜色的名字和hex值, 获取单点颜色值 (要求Android 5+) – 按键映射 – 解锁屏幕 – 文字识别，二维码识别 2. 事件: – 监听实体按键 (例如音量键) – 监听触屏 (点击 , 长按, 滚动) – 监听手势 (滑动) – 监听屏幕刷新\nSecureTask:\n管理应用：安装，卸载，杀死，冻结\n管理系统安全类的设置：辅助功能等\n管理系统锁屏，锁屏签名\nNotification Listener:\n只能读取标准的Android通知，因此对于某些应用程序，可能仅读取一部分内容。 通知监听器是一个简单的Tasker插件，用于读取其他应用程序的通知。您可以： 1）创建事件以拦截通知； 2）删除全部或部分通知； 3）对通知数据库执行查询； 4）显示代码（Marshamallow +）； 5）自动回复邮件（Lollipop +）； 6）点击通知或通知按钮； 7）使用自定义字段创建通知； 8）序列化/反序列化通知，以便通过网络传输通知； 9）对Lollipop +采取呼叫行动。 要求： Tasker版本4.7+\nTasker 插入代码 # adb shell command # 创建任务时选择 ADB Wifi，并在“命令”处输入命令。\nJava 代码 # 需要注意的是，Tasker 不支持运行你写好的 Java 代码。\nIt does not allow you to \u0026lsquo;write Java code\u0026rsquo;\u0026hellip; but the combination of Tasker\u0026rsquo;s logic and flow control with direct access to the Android API is sufficient for most automation purposes.\n使用方式是选择 Java 函数，然后在“类或对象”里选 Android API 提供的类或对象，然后在“功能”中选择类方法，如果该方法有参数，就在“参数”中指定参数的值；如果该方法有返回值，可以指定返回值的名称……（实在麻烦，此处应有“让苍天知道我认输”图）\nJavascript 代码 # 如果选择了 Javascriptlet，可以直接复制黏贴 JS 代码。注意 JS 代码里使用的函数需要是 Tasker 支持的内建函数。\nTasker makes most of it\u0026rsquo;s actions available via functions which can be called directly via name in JavaScript(let) actions and WebView elements.\n如何实现多点连续滑动（用于滑动图案解锁） # 插件录制 # 中文名：按键录制 Pro\n英文名：RepetiTouch Pro\n下载该插件可能需要独特的网络环境。网友表示这个软件十分好用，美中不足是需要 root 权限。\nadb shell # 前面说过 input swipe 方法不能实现连续滑动。为了解决这个问题，只能使用 sendevent 了。\n用户在硬件设备上点击后，程序中的 OnClickListener 如何收到这个事件呢？大致的流程如下：\n用户点击→（硬件驱动部分）硬件产生一个中断→/dev/input/event*写入一个相应的信号→循环读取/dev/input/event*的事件→分发给WindowManagerServer→最后再发到相应的ViewGroup和View\n因此我们可以通过 getevent 和 sendevent 命令来获取点击的事件、或者模拟点击事件。\n如 adb shell getevent event0 的输出：\n/dev/input/event0: 0003 0039 00000c3a /dev/input/event0: 0001 014a 00000001 /dev/input/event0: 0001 0145 00000001 /dev/input/event0: 0003 0035 00000124 /dev/input/event0: 0003 0036 00000393 /dev/input/event0: 0003 0031 00000005 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0031 00000006 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0030 00000007 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0030 00000006 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0036 00000391 /dev/input/event0: 0003 0030 00000007 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0036 0000038f /dev/input/event0: 0003 0030 00000006 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0035 00000125 /dev/input/event0: 0003 0036 00000389 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0035 00000126 /dev/input/event0: 0003 0036 00000380 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0035 00000133 /dev/input/event0: 0003 0036 00000353 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0035 0000013a /dev/input/event0: 0003 0036 00000341 /dev/input/event0: 0003 0031 00000005 /dev/input/event0: 0000 0000 00000000 .... /dev/input/event0: 0003 0035 0000031c /dev/input/event0: 0003 0036 000002a3 /dev/input/event0: 0000 0000 00000000 /dev/input/event0: 0003 0039 ffffffff /dev/input/event0: 0001 014a 00000000 /dev/input/event0: 0001 0145 00000000 /dev/input/event0: 0000 0000 00000000 sendevent 的命令格式：\nadb shell sendevent device type code value device:\n安卓可以使用 adb shell cat /proc/bus/input/devices 查看。\n鸿蒙会报无权限，我经过遍历尝试发现 event3 对应 touch 事件。\ntype:\n0000 Synchronization events\n0001 Keys and buttons\n0003 Absolute axes，即描述运动事件的值\ncode:\n0000 0000 SYN_REPORT，这里笔者简单理解为与io的flush类似\n0003 0039 开始接触设备的唯一标识号，这里为0xc3a, 0xffffffff代表结束接触\n0001 014a 标明触摸事件，1代表按下，0代表放开\n0001 0145 表明是用手指触摸的，同样1代表按下，0代表放开\n0003 0035 触摸的x坐标\n0003 0036 触摸的y坐标\n0003 0030 接触面椭圆长轴，非必需\n0003 0031 接触面椭圆短轴，非必需\nJava 代码 # 这篇博客 的作者还提供了可以实现模拟滑动的 Java 类，通过代码可以对上述 sendevent 过程有更深刻的理解。\npublic static void swipeStart() { sendEvent(EV_ABS, ABS_MT_TRACKING_ID, parseTrackingId()); sendEvent(EV_KEY, BTN_TOUCH, PRESS_DOWN); sendEvent(EV_KEY, BTN_TOOL_FINGER, PRESS_DOWN); } private static final int SWIPE_RUN_INTERVAL = 50; public static void swipeRun(int x1, int y1, int x2, int y2) { // TODO: emulate touch press 3-0x30 3-0x31 int xStep = (x2 - x1) / SWIPE_RUN_INTERVAL; int yStep = (y2 - y1) / SWIPE_RUN_INTERVAL; int x = x1, y = y1; for (int step = 0; step \u0026lt;= SWIPE_RUN_INTERVAL; ++step) { sendEvent(EV_ABS, ABS_MT_POSITION_X, x); sendEvent(EV_ABS, ABS_MT_POSITION_Y, y); sendEvent(EV_SYN, SYN_REPORT, 0); x += xStep; y += yStep; } } public static void swipeEnd() { sendEvent(EV_ABS, ABS_MT_TRACKING_ID, TRACKING_END); sendEvent(EV_KEY, BTN_TOUCH, PRESS_UP); sendEvent(EV_KEY, BTN_TOOL_FINGER, PRESS_UP); sendEvent(EV_SYN, SYN_REPORT, 0); } EventEmulator.swipeStart(); EventEmulator.swipeRun(357, 2054, 1112, 1308); EventEmulator.swipeRun(1112, 1308, 1112, 2032); EventEmulator.swipeEnd(); 使用 Tasker 的一些注意事项 # （持续更新中……）\nTasker 和对应的插件必须允许后台常驻，有些插件（比如 TouchTask）可能需要开启无障碍辅助功能。\n参考教程 # [1] Tasker 自动化，实现网课自动打卡签到：https://www.bilibili.com/s/video/BV1mE411H7az\n[2] 安卓定时自动打开钉钉考勤打卡：https://www.jianshu.com/p/7ca93f87a25c\n[3] 利用 Tasker 打造最强自动签到神器：https://102345.xyz/jishu/tasker/#toc-head-3\n[4] 华为手机（鸿蒙 OS）开启 adb 调试权限：https://blog.csdn.net/ckckjsws/article/details/123849295\n[5] How to Install ADB on Windows, macOS, and Linux: https://www.xda-developers.com/install-adb-windows-macos-linux/\n[6] 安卓通过 adb 模拟键盘输入、点击屏幕、滑动、按键：https://blog.51cto.com/hspbc/5050990\n[7] 通过 sendevent 实现多点连续滑动：https://bbs.pediy.com/thread-252052.htm\n[8] Android 通过指令模拟 touch 滑动解锁：https://blog.csdn.net/xiaobaiing/article/details/51363835\n[9] android 在 adb 下模拟长按事件：https://zhuanlan.zhihu.com/p/26236061\n[10] Tasker 下载：https://taskerm.com/tasker-download\n[11] Tasker Java Support: https://tasker.joaoapps.com/userguide/en/java.html\n[12] Tasker Javascript Support: https://tasker.joaoapps.com/userguide/en/javascript.html\n"},{"id":12,"href":"/post/2021-11-05-something_about_install_from_source_code/","title":"something about installing from source code","section":"Posts","content":" 几种常见的安装方式 (Linux) # apt system # 根据 Debian 官网上的定义：\nBeing able to install and remove packages is great, but the basic software for doing this (known as dpkg) does exactly that and nothing more. This is fine if you download one or two packages by hand, but quickly becomes cumbersome when you are trying to manage a large number of packages. Furthermore, if your shiny new package requires software you haven\u0026rsquo;t yet installed, you have to download the newly required software by hand. And if you later decide to remove the no-longer-shiny package, these extra packages will linger on your system, consuming hard drive space, unless you manually remove them.\nObviously, all of this manual labor is a tedious chore, and so most package management systems come with software which takes care of some or all of it for you. apt is a common base on which to build these programs: in addition to aptitude, programs such as synaptic and apt-watch make use of apt.\napt works by keeping a list of the packages that can be downloaded from Debian on your computer. This list is used to find packages that need to be upgraded and to install new packages. apt can also solve many dependency problems automatically: for instance, when you choose to install a package, it will find any additional required packages and install those as well.\nWhen working with a package manager based on apt, such as aptitude, you will typically perform three basic tasks: you will update the list of packages that are available by downloading new lists from the Debian servers, you will select which packages should be installed, upgraded, or removed, and finally, you will commit your selections by actually performing the installations, removals, etc.\napt-based package managers read the list of “sources” \u0026ndash; repositories of Debian packages \u0026ndash; from the file /etc/apt/sources.list. The format and contents of this file are beyond the scope of this document, but are described in the manual page sources.list(5).\n其主要优点是：可以根据软件的依赖自动帮你下载依赖中的 packages，无需一个个手动下载；同时，如果要卸载软件，也会根据总体的依赖情况帮你卸载掉当初引入且不被其他 package 所依赖的 extra packages.\n其工作方式是：首先读取 sources list（位于 /etc/apt/sources.list）（它的格式就不细讲了，差不多理解就行），逐一地访问 uri 上的 packages.gz 文件检查依赖（如 https://mirrors.tuna.tsinghua.edu.cn/debian/dists/bookworm/main/binary-amd64/packages.gz ），确定涉及的 package，然后去找需要安装的“东西”。找到的是什么东西呢？是以 .deb 为后缀的文件，它可以通过 sudo dpkg -i 软件包名.deb 的方式安装。并将从 uri 获得的 deb 文件放置在 /var/cache/apt/archives\ndpkg 如何安装 deb 呢，参考这里的回答：\nextract the package and copy the content to the right location, and check for pre-existing files and modifications on them, run package maintainer scripts: preinst, postinst, (and prerm, postrm before these, if a package is being upgraded) execute some actions based on triggers 从源代码安装 # 顾名思义，手头只有某个 package 的源代码和相应的构建工具，只能亲自让代码-\u0026gt;二进制程序+头文件，并让这些二进制程序和头文件归位，以便编译和运行我自己的代码的时候可以找到它们。\n为什么要从源码安装 # 转眼间，距离上一次写（shui）技术博客已经整整 4 个月了，这 4 个月经历了人生中第一份实习，还打了一场保研之战，终于都过去了。\n上个学期以来，我差不多 install from source 了以下一些东西：g++/gcc, python3, opencv, （某家的）mpi，踩了一些坑，发现了一点规律，就此记录。\n不得不从源码安装的理由无非是 sources.list 里面没找到我们想安装的东西，一般都是太老或者太新的版本。当然，sources.list 里面有什么，和系统版本也是有关的。\n从源码安装的基本步骤 # 由于各种库都大同小异，因此从 GCC 入手介绍。\n在 GNU GCC 的官网上可以看到如下步骤：\nprerequisites downloading the source configuration building testing (optional) final installation prerequisites # 其实是从源码安装所需要的基本工具，比如安装新版本的 GCC 需要：\nISO C++11 compiler（一般是系统自带的） C standard library and headers (C 标准库和头文件) gzip or bzip2 or tar（下载代码一定是压缩后文件，因此也必须拥有解压工具） GNU make（基础构建工具） GNU Multiple Precision Library (GMP is a free library for arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers.) GNU MPFR Library (The MPFR library is a C library for multiple-precision floating-point computations with correct rounding.) MPC Library (a C library for the arithmetic of complex numbers with arbitrarily high precision and correct rounding of the result.) 等条件。（可以看到后面三个和算术运算有关系，神秘）\ndownloading the source # 使用 git 或者 wget 就可以将网上分发的代码下载到自己的电脑上啦！\n当然，如果服务直接访问某些网站不太行，就自己下载以后 scp 传到服务器上吧~\nconfiguration # Like most GNU software, GCC must be configured before it can be built.\n顾名思义，这是通过选项，给后面的 build \u0026amp; install 阶段做配置（比如要挑选哪些部分来 build），生成对应配置的 Makefile 文件。\n有两个概念，一个是 srcdir，代表 GCC source repository 的顶层目录，一个是 objdir，代表的是 build/object 文件夹的顶层目录。\n一般来说，srcdir 和 objdir 最好是单独的两个文件夹，且 objdir 不要是 srcdir 的子文件夹；srcdir = objdir 的情况可能可以成功，但是不推荐。\n进行配置的步骤基本是：\n% mkdir objdir % cd objdir % srcdir/configure [options] [target] Host, Build and Target Specification # Specify the host, build and target machine configurations. You do this when you run the configure script.\nThe build machine is the system which you are using, the host machine is the system where you want to run the resulting compiler (normally the build machine), and the target machine is the system for which you want the compiler to generate code.\nbuild machine 是现在使用的系统，host machine 是希望运行生成的编译器的系统（通常就是 build machine），target machine 是希望编译器为其生成代码的系统。\n补充知识:\nTriple:\n通用形式是：\u0026lt;arch\u0026gt;\u0026lt;sub\u0026gt;-\u0026lt;vendor\u0026gt;-\u0026lt;sys\u0026gt;-\u0026lt;abi\u0026gt;\narch = x86_64, i386, arm, thumb, mips, etc sub = for ex. on ARM: v5, v6m, v7a, v7m, etc vendor = pc, apple, nvidia, ibm, etc sys = none, linux, win32, darwin, cuda, etc abi = eabi, gnu, android, macho, elf, etc (关于 abi 是什么，就不在这里详细介绍了，新的博客提上日程啦) Options Specification # 下面列出几个常用的:\n--prefix=dirname: Specify the toplevel installation directory. This is the recommended way to install the tools into a directory other than the default. The toplevel installation directory defaults to /usr/local. We highly recommend against dirname being the same or a subdirectory of objdir or vice versa. If specifying a directory beneath a user’s home directory tree, some shells will not expand dirname correctly if it contains the ‘~’ metacharacter; use $HOME instead.\n和 prefix 有关的还有，但 Normally you should not need to use these options --exec-prefix=dirname: Specify the toplevel installation directory for architecture-dependent files. The default is prefix. --bindir=dirname: Specify the installation directory for the executables called by users (such as gcc and g++). The default is exec-prefix/bin. --program-prefix=prefix, --program-suffix=suffix: This option prepends prefix/suffix to the names of programs to install in bindir (see above). For example, specifying \u0026ndash;program-prefix=foo- would result in ‘gcc’ being installed as /usr/local/bin/foo-gcc.\n--with-local-prefix=dirname: Specify the installation directory for local include files. The default is /usr/local. Specify this option if you want the compiler to search directory dirname/include for locally installed header files instead of /usr/local/include.\nYou should specify \u0026ndash;with-local-prefix only if your site has a different convention (not /usr/local) for where to put site-specific files.\nThe default value for \u0026ndash;with-local-prefix is /usr/local regardless of the value of \u0026ndash;prefix. Specifying \u0026ndash;prefix has no effect on which directory GCC searches for local header files. This may seem counterintuitive, but actually it is logical.\n这说明即便将 include 的头文件放在了 prefix 下且把 \u0026ndash;with-local-prefix 设置成为了 prefix，在编译时如果不加 -I 的编译选项指定头文件位置，编译器默认是不会去 prefix/include 文件夹搜索头文件的。这个选项在编译多个不在同一个目录下的文件非常有用。\nBoth the local-prefix include directory and the GCC-prefix include directory are part of GCC’s “system include” directories.\nBoth the local-prefix include directory and the GCC-prefix include directory are part of GCC’s “system include” directories. Although these two directories are not fixed, they need to be searched in the proper order for the correct processing of the include_next directive. The local-prefix include directory is searched before the GCC-prefix include directory. Another characteristic of system include directories is that pedantic warnings are turned off for headers in these directories.\n一个疑问是：local-prefix include dir 和 GCC-prefix include dir 有什么区别呢？\n--disable-multilib: Specify that multiple target libraries to support different target variants, calling conventions, etc. should not be built. The default is to build a predefined set of them.\n--enable-languages=lang1,lang2,…: Specify that only a particular subset of compilers and their runtime libraries should be built. For a list of valid values for langN you can issue the following command in the gcc directory of your GCC source tree: grep ^language= */config-lang.in\nBuilding # Build a native compiler # 执行 make 命令，对 GCC 的源码进行编译\nBuild a cross compiler # When building a cross compiler, it is not generally possible to do a 3-stage bootstrap of the compiler. This makes for an interesting problem as parts of GCC can only be built with GCC.\nTo build a cross compiler, we recommend first building and installing a native compiler. You can then use the native GCC compiler to build the cross compiler. The installed native compiler needs to be GCC version 2.95 or later.\nTesting # 测试阶段。对于 GCC 主要测试：\nThis will test various components of GCC, such as compiler front ends and runtime libraries.\n源自维基百科：\nThe front end analyzes the source code to build an internal representation of the program, called the intermediate representation (IR). It also manages the symbol table, a data structure mapping each symbol in the source code to associated information such as location, type and scope.\nline reconstruction preprocessing lexical analysis syntax analysis semantic analysis Installation # cd objdir \u0026amp;\u0026amp; make install\nWe strongly recommend to install into a target directory where there is no previous version of GCC present.\n这一步就是把编译所得的产物和相应的头文件放在合适的位置（可能需要管理员权限）。具体地：\nuser level binaries can be found in prefix/bin where prefix is the value you specified with the \u0026ndash;prefix to configure (or /usr/local by default). (If you specified \u0026ndash;bindir, that directory will be used instead; otherwise, if you specified \u0026ndash;exec-prefix, exec-prefix/bin will be used.) Headers for the C++ library are installed in prefix/include; libraries in libdir (normally prefix/lib); internal parts of the compiler in libdir/gcc and libexecdir/gcc; documentation in info format in infodir (normally prefix/info).\n还有一种写法是：\nmake DESTDIR=path-to-rootdir install\nDESTDIR 是什么呢？\nhttps://petsc.org/release/install/install/#installs-for-package-managers-using-destdir-very-uncommon\nhttps://stackoverflow.com/questions/11307465/destdir-and-prefix-of-make\nhttps://www.gnu.org/software/automake/manual/html_node/DESTDIR.html\n可以看到这个选项是为 Package Managers 准备的，因为这些人需要知道 install 的时候安装了哪些文件，使用　DESTDIR　选项（绝对路径）后，会将所有文件安装到 ${DESTDIR}/prefix/ 下。方便其打包。\n"},{"id":13,"href":"/post/2021-05-09-python3_on_windows/","title":"windows python3 or python?","section":"Posts","content":" 神奇现象 # 一直以来,对于 python 和 python3,我都是这样记忆的: linux 上 pip3 和 python3, windows 上 pip 和 python\n但在做作业的时候, 忘了自己在 windows 上, 于是 python3 ./load_data.py 就这么顺手打出来了, 可是什么也没有发生. 经检查不是代码的问题,毕竟 print() 都没执行, 最后发现应该用 python 来执行命令. 那么问题来了:\n为什么 python3 执行时没有报错: no such command 在 powershell 中输入 python3 后跳到了microsoft store? 但我显然不会通过此途径下载 python 在 powershell 中输入 where python3 后,得到的结果是 C:\\Users\\******\\AppData\\Local\\Microsoft\\WindowsApps\\python3.exe, 而输入 where python 后, 得到的结果是 D:\\ProgramData\\Anaconda3\\python.exe 和 C:\\Users\\******\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe. 说明python3.exe 是存在的, 只不过安装的方式比较特别 于是终极问题是: 为什么用这个 python3.exe 执行代码, 不报错但也什么都没有发生? 直观感觉这个 python3.exe 的运行环境肯定是存在问题的(我最初以为是后台下载的时候网络还是什么东西出问题了导致环境不全). 或者说, 它是什么?\n解释 # 本篇参考如下博客: 迷惑行为：Win10 中的 Python: https://shuhari.dev/blog/2019/11/win10-store-python\n大概是因为, 微软试图让 windows 自带 python 环境(这个看上去很容易办到, 但是为啥非要以这个方式实现呢?疑惑) 它的作用在于当调用 python/python3 命令时, 自动跳转到 microsoft store 下载. 可是如下的结果确实说明这个方法不一定对每位用户都是一个好的选择:\n实话说用 microsoft store 下载东西好像体验一直不是很好\u0026hellip;..\n不过上述功能可以通过\u0026quot;应用程序别名\u0026quot;关闭掉:\npython3 or python # 最后的问题: why python3 on OSX and linux, but python on windows?\nso上是这样说的:\nOSX and Linux have python executable installed by default as a rule and it refers to Python 2 version in most cases at the moment that is why you need a separate python3 name there. There is no Python on Windows by default. And therefore any version that you\u0026rsquo;ve installed is just python (I guess). The recommended way to manage multiple python versions is to use the Python launcher.\n看来等 windows 也有自带的 python 的时候,也得用 python3 跑程序了.\n"},{"id":14,"href":"/post/2021-01-22-windows%E9%87%8D%E8%A3%85%E5%92%8C%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/","title":"win10 or Linux? 我都要","section":"Posts","content":" TL; DR # 总的来讲这两天就做了下面几件事情\n重装 windows 系统\n制作 windows 启动盘（ \u0026gt; 8G ）\n修改系统盘的Partition table格式：MBR to GPT\n对系统盘进行格式化并重新分区\n修改 windows 系统所在分区的文件系统： NTFS to FAT32\n正式开始重装\n安装 Ubuntu 双系统\n制作 Ubuntu 启动盘 开始重装 设置分区 安装显卡驱动 安装输入法 修改 grub 以修改默认启动顺序 各种其他环境的配置（ to be continued ） 前言 # 其实去年暑假就打算重装一下电脑了，但当时把其他事情的优先级放置得比较靠前就没开搞。再加上大三上的各种大作业的环境配置，让我感觉没有一个原生的Linux环境真是太麻烦了（尽管有 wsl2 但还是没有在用 Linux 的感觉）……所以趁此寒假赶紧开始。\n谨以此文纪念寒假中花在这件事上的三天，并感谢某可爱在此过程中给予的关心和帮助~笔芯~:kissing_heart:\n第一部分：重装windows # 参考链接\n先讲讲我这台电脑在此之前的基本信息吧\nSSD: MBR, NTFS, 128G HDD: GPT, NTFS, 1T BIOS: Legacy BIOS Memory: 8G GPU: NVIDIA GEFORCE GTX 1050 由于我之后需要安装 Ubuntu 双系统，参考这篇博客后发现 UEFI 引导比较稳妥，因此决定摒弃 Legacy BIOS 。但 UEFI 要求系统盘对应的分区表是 GPT ，因此肯定需要做从 MBR 到 GPT 的修改；但电脑在运行操作系统的时候肯定不能对 C 盘进行该修改，一番搜索后发现安装过程中按 Shift+F10 （有的电脑需要加Fn）可以调出 windows 命令行（不过此时操作系统尚未装好，一些命令是无法使用的）此时可以通过 diskpart 命令对磁盘进行格式化、分区、分区表转换等操作。\n可是做到这些还不够。点击相应的分区准备开始安装 windows 的时候，又报错了，提示对应分区的文件系统应该是 FAT32 而非 NTFS 。于是还需要针对安装 windows 的分区进行转换。\n详细的步骤见后面各个部分。\n制作启动盘 # 使用的就是微软提供的小工具 MediaCreationTool\n下载地址：https://www.microsoft.com/zh-cn/software-download/windows10\n把 U 盘插入电脑后，等待工具进行完下载和创建介质两步就可以啦！\n似乎有个通用的工具叫做Rufus。\n提示：网络情况不佳时，这一步会耗费几个小时。\n开始重装 # 除了以下几点，几乎就是一路 next 了。\nMBR to GPT # 除了点击 Shift+F10 调出命令行以外，参考 Microsoft Docs 的这篇文档\n先解释以下各个名词的意思\nBIOS: Basic Input/Output System\nUEFI: Unified Extensible Firmware Interface\nMBR: Master Boot Record，又叫做主引导扇区是计算机开机后访问硬盘时所必须读取的首个扇区，在硬盘上的三维地址为 (柱面，磁头，扇面) = (0, 0, 1)\nMBR的组成：启动代码，硬盘分区表，结束标志字\nGPT: GUID Partition Table，全局唯一标识磁盘分区表。\nUEFI可识别MBR和GPT，因此在UEFI中这两个磁盘都可以用来存储数据，但鉴于微软的显示，若你的操作系统是使用windows程序安装的，在UEFI下只能将操作系统安装至GPT磁盘中\nIn addition to the standard PC disk partition scheme that uses a master boot record (MBR), UEFI also works with the GUID Partition Table (GPT) partitioning scheme, which is free from many of the limitations of MBR.\n因此其实 UEFI 也是支持 MBR 的，只是微软没有提供这样的选项。（不过这个选择也可以理解，瞄了一眼 UEFI Specification 2.6, 发现 GPT 竟然是在这个规范里定义的，打扰了）\n另外，MBR 最多支持 2T ，但 GPT 理论上没有容量限制。\nNTFS to FAT32 # 具体操作其实就是通过 Shift+F10 调出命令行以后执行以下命令：\n（注意需要针对具体某个分区进行格式化）\n\u0026gt; diskpart \u0026gt; list disk \u0026gt; select disk 0 \u0026gt; select partition 3 \u0026gt; format fs=fat32 (quick) NTFS: New Technology File System\nFAT32: File Allocation Table\nWhat is ESP?\n摘自ArchWiki\nEFI 系统分区(也称为 ESP 或者 EFISYS)是一个 FAT32 格式的物理分区 (在硬盘主分区表上，而不是 LVM 或软件 RAID 等等) ，从这里 UEFI 固件启动 UEFI 引导器和应用程序。\n它与操作系统无关而是作为 EFI 固件要启动的引导器和应用程序的存储空间，是 UEFI 启动所必须。\n推荐使用 GPT 和 UEFI 搭配因为有的 UEFI 固件不支持 UEFI-MBR 启动。\nWarning: 如果在 UEFI/GPT 系统上配置 双启动，请不要重新格式化 UEFI 分区，因为已有的分区上包含 Windows 启动需要的 .efi 文件。不需要重新创建分区，只需要 #挂载分区.\n摘自wikipedia\nThe EFI (Extensible Firmware Interface) system partition or ESP is a partition on a data storage device (usually a hard disk drive or solid-state drive) that is used by computers adhering to the Unified Extensible Firmware Interface (UEFI). When a computer is booted, UEFI firmware loads files stored on the ESP to start installed operating systems and various utilities.\nAn ESP contains the boot loaders or kernel images for all installed operating systems (which are contained in other partitions), device driver files for hardware devices present in a computer and used by the firmware at boot time, system utility programs that are intended to be run before an operating system is booted, and data files such as error logs.\n第二部分：安装 Ubuntu # 制作启动盘 # 使用的 ISO 镜像文件：https://mirrors.bfsu.edu.cn/ubuntu-releases/focal/ubuntu-20.04.1-desktop-amd64.iso\n使用的烧录软件：balenaEtcher\n开始重装 # 参考的教程：\nhttps://www.cnblogs.com/masbay/p/10745170.html\n其中最重要的是分区的那一步。在此前我已经通过 windows 将 G 盘通过 shrink volume 的方式获得了 80G 的未使用空间分别挂载到 swap, /, /home，另外，efi 也需要大约 200MB 的系统盘空间。\n安装显卡驱动 # 有两种方式\n去 NVIDIA 官网下载对应的驱动程序并安装（可能有坑）\n通过 Software \u0026amp; Updates 的 Additional Drivers 找到对应的驱动版本，需要改动的就改动。\n安装输入法 # 默认使用的语言输入系统是 IBus，能用的只有 Intelligent Pinyin 了，而且也不怎么智能。\n遂安装搜狗输入法。具体步骤参考官网\n安装 fcitx 后，还需要进行如下配置。\n点击进入输入法配置。\n点击+号，添加sougoupinyin\n进入全局配置\n默认切换输入法的快捷键是 Ctrl+Space，但和 windows 下的不同。为了保持一致性并防止热键冲突，将系统的 Super+Space 热键屏蔽掉，并改成 Super+Space\n设置启动顺序 # 先安装 windows 后安装 Ubuntu 后，是 Ubuntu 引导 windows。而默认的选项在 Ubuntu 上，如何改成 Windows Boot Manager 呢？\n参考\n在我的电脑中，Windows Boot Manager 位于第三位，因此 set default=\u0026ldquo;2\u0026rdquo;\n后记 # 其实整个过程并不算很顺利。系统安装中有一些限制是在进行到后面的步骤后报错了才知道的。\n另外，刚刚安装 Ubuntu 后整个人处于比较懵的状态，尤其是发现 vim 的操作已经忘了很多了，一开始换源的时候费了很大力。第二天开机发现了一个很大的问题是，可能因为显卡驱动的原因，无法调节屏幕亮度，甚至都没有调节屏幕亮度的那个小条。神奇的是重启之后就好了。\n总而言之就是多试错吧。毕竟最坏的结果就是再来一次重装。windows 重装中的几乎每个问题，都是新的重装过程中冒出来的，由此可见这两天我的电脑反复开关机了很多次。\n另外有两个问题之后再填坑：\nUbuntu 关机后启动 windows，发现 windows 系统时间错误，需要手动同步。 Ubuntu 在明明有网但信号较弱时，已经成功连接却显示\u0026quot;?\u0026quot;，而且也无法访问网络。 Upd: 发现信号较强时也可能显示\u0026quot;?\u0026quot; "},{"id":15,"href":"/post/2020-09-23-git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/","title":"git学习笔记(2)","section":"Posts","content":" git学习笔记(2) # 在上周一直说要学习git的另外三个比较常见的操作，可是因为各种原因一直拖着没学。明日复明日，明日何其多！\n于是下定决心趁着今天做软工小作业，就把这三个git操作学习一番。\n声明：本博客并非作者的原创内容！因为是git新手，所以本系列文章主要提炼了参考网站上的内容，而几乎没有自己的实操经验，只是为了便于未来查阅。如要详细了解对应内容，请点击进入原网站查看。\n1. git rebase（奇妙与危险相伴） # 参考1\n参考2\n在Git中整合来自不同分支的修改主要有两种方法：merge和rebase（变基）。变基顾名思义就是在commit history上看，在某一分支上做的修改“好像”是直接在另一分支上进行的一样。\n基本操作 # 以下图为例：\n如果想要将experiment分支上的修改整合到master分支上，那么最简单的方法是合并。\n但也可以提取C4中引入的修改，再在C3的基础上应用一次。这种操作就叫做rebase。\n$ git checkout experiment\t# 检出experiment分支 $ git rebase master\t# 变基到master分支上 变基后的结果为： 查看一个经过变基的分支的历史记录时会发现，尽管实际的开发工作是并行的， 但它们看上去就像是串行的一样，提交历史是一条直线没有分叉。\n使用场景(!!!) # 首先我们来看上述参考网站中的一段原文：\n变基的风险 呃，奇妙的变基也并非完美无缺，要用它得遵守一条准则： 如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基。 如果你遵循这条金科玉律，就不会出差错。 否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。\n正确用法：一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁——例如向某个其他人维护的项目贡献代码时。 在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将你的代码变基到 origin/master 上，然后再向主项目提交修改。 这样的话，该项目的维护者就不再需要进行整合工作，只需要快进合并便可。\n错误用法：变基操作的实质是丢弃一些现有的提交，然后相应地新建一些内容一样但实际上不同的提交。 如果你已经将提交推送至某个仓库，而其他人也已经从该仓库拉取提交并进行了后续工作，此时，如果你用 git rebase 命令重新整理了提交并再次推送，你的同伴因此将不得不再次将他们手头的工作与你的提交进行整合，如果接下来你还要拉取并整合他们修改过的提交，事情就会变得一团糟。\ntrade-off # 那么在项目中究竟是使用合并还是变基？首先需要考虑commit history的意义。\n一种观点是，仓库的提交历史是对事实的记录。它是针对历史的文档，本身就有价值，不能乱改。 从这个角度看来，改变提交历史是一种亵渎，你使用 谎言 掩盖了实际发生过的事情。 如果由合并产生的提交历史是一团糟怎么办？ 既然事实就是如此，那么这些痕迹就应该被保留下来，让后人能够查阅。\n另一种观点则正好相反，他们认为提交历史是 项目过程中发生的事。 没人会出版一本书的第一版草稿，软件维护手册也是需要反复修订才能方便使用。 持这一观点的人会使用 rebase 及 filter-branch 等工具来编写故事，怎么方便后来的读者就怎么写。\n总的原则是，只对尚未推送或分享给别人的本地修改执行变基操作清理历史， 从不对已推送至别处的提交执行变基操作，这样，你才能享受到两种方式带来的便利。\n2. git cherry-pick # git cherry-pick 教程\n对于多分支的代码库，将代码从一个分支转移到另一个分支，如果我们需要另一个分支的所有代码变动，那么就采用合并git merge的方式。如果我们只需要部分的代码变动（某几个提交），这时就采用git cherry-pick。\n（图源：https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html）\n基本操作 # $ git cherry-pick \u0026lt;commitHash\u0026gt; 将指定的提交应用于当前分支。会在当前分支产生一个新的提交，并且这两个内容相同的提交hash值不同。\na - b - c - d Master \\ e - f - g Feature 将f应用到master分支\n$ git checkout master\t# 切到master分支 $ git cherry-pick f\t# cherry-pick 结果为：\na - b - c - d - f Master \\ e - f - g Feature git cherry-pick命令的参数，不一定是提交的哈希值，分支名也是可以的，表示转移该分支的最新提交。\n$ git cherry-pick feature 上面代码表示将feature分支的最近一次提交，转移到当前分支。\n解决冲突 # 如果操作过程中发生代码冲突，cherry-pick 会停下来，让用户决定如何继续操作。（下面整个流程都有点像merge过程）\na. --continue # 用户解决代码冲突后，第一步将修改的文件重新加入暂存区（git add .），第二步使用下面的命令，让 cherry-pick 过程继续执行。\nb. --abort # 发生代码冲突后，放弃合并，回到操作前的样子。\nc. --quit # 发生代码冲突后，退出cherry-pick，但是不回到操作前的样子，这种情况下当前分支中未冲突的内容状态将为modified\n--quit\nForget about the current operation in progress. Can be used to clear the sequencer state after a failed cherry-pick or revert.\n仓库之间的转移 # cherry-pick命令不仅可以合并同一个仓库的不同分支的提交，还可以合并不同仓库的提交，方法是先将该库加为远程仓库。\n因此如果想要将远程仓库A的内容添加到本地仓库B中，首先要在将A添加为B的远程仓库之一，再git fetch A, 再使用git cherry-pick \u0026lt;commitHash\u0026gt;转移提交。\n$ git remote add target git://giturl $ git fetch target $ git log target/master\t# 找到要合并的那个commit $ git cherry-pick \u0026lt;commitHash\u0026gt; cherry-pick潜在的问题 # TL; DR # Raymond Chen在《The Old New Thing》中写了10篇文章阐述在项目中最好使用merge而非cherry-pick的原因，并提出解决/替代办法。（实在是太长了，只看了前2篇……）\n索引如下：\nhttps://devblogs.microsoft.com/oldnewthing/20180323-01/?p=98325\n原因 # Part1: bad\nBasically, when you cherry-pick a commit, you now have two copies of the commit sitting in the graph. Any lines of code affected by that commit must remain untouched in both branches until the two copies of the commit finally merge. If either branch modifies any line touched by the cherry-pick, then that creates a powderkeg that can sit quietly indefinitely. It is at the time somebody tries to merge the two commits together that the explosion occurs, and that point could be in a faraway place not immediately related to the branches involved in the cherry-pick. This means that the person trying to resolve the merge was never part of the cherry-pick madness and may not know who to talk to in order to figure out what happened.\n由于cherry-pick会产生两个内容相同但是在提交历史上没有父子关系的commit，因此不能在二者最终合并前对那次提交的任何内容进行修改！（因为一旦修改必然会产生冲突，而且这个冲突不是立马显现的，很可能在之后让别的不知情分支遭殃！）\nPart2: worse\nBut you know what’s worse than a merge conflict?\nNo merge conflict.\n本质上是three-way merge算法中会认为某两个commit是一样的。\nNow we perform the merge. Git looks for a merge base, which is commit A, the most recent common ancestor between the two branches. Git then performs a three-way merge using A as the base, M3 as HEAD, and F3 as the inbound change. All that matters now is the delta between the base and the two terminal commits, so let’s remove the irrelevant commits from the diagram.\nComparing the base to the head of the master branch, we see that apple changed to berry. Comparing the base to the head of the feature branch, we see that apple didn’t change at all.\n3. git pull # 基本用法 # git pull命令的作用是：取回远程主机某个分支的更新，再与本地的指定分支合并，它的完整格式稍稍有点复杂。\n$ git pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt; : \u0026lt;本地分支名\u0026gt; 例如，取回origin主机的next分支，并与本地的master分支合并；因此pull= fetch + merge。\n$ git pull origin next : master 如果远程分支next要与当前分支合并，则冒号后面的部分可以省略。\n$ git pull origin next # 这等同于 $ git fetch origin $ git merge origin/next 注意：在某些场合，git会自动在本地分支与远程分支之间建立追踪关系，如在git clone时，所有本地分支默认与远程主机的同名分支建立追踪关系，也就是说本地的master分支自动关联origin/master分支。\n手动建立追踪关系：\n指定master分支追踪origin/next分支。\n$ git branch --set-upstream master origin/next 如果当前分支和远程分支存在追踪关系，则git pull就可以省略远程分支名。本地的当前分支自动与对应origin主机的追踪分支合并。\n$ git pull origin 如果当前分支只有一个追踪分支，则连远程主机名都可以省略。\n$ git pull 更保险的用法 # $ git fetch origin master : temp\t# 在本地新建一个temp分支，并将远程origin仓库的master分支代码下载到temp分支 $ git diff temp\t# 来比较本地代码与刚刚远程下载下来的代码的区别 $ git merge temp # 合并temp分支到本地的master分支 $ git branch -d temp\t# 如果不想保留temp分支，可以将其删除 强制pull覆盖当前分支（慎用） # $ git fetch --all $ git reset --hard origin/master $ git pull "},{"id":16,"href":"/post/2020-09-15-git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"git学习笔记(1)","section":"Posts","content":" git学习笔记(1) # 声明：本博客并非作者的原创内容！因为是git新手，所以本系列文章主要提炼了参考网站上的内容，而几乎没有自己的实操经验，只是为了便于未来查阅。\n1. fast forward \u0026amp; no fast forward # 在当前分支合并到另一分支时，如果没有冲突需要解决，就会直接移动文件指针。这个过程叫做fast forward。\n举个例子：\n开发一直在master分支进行，但忽然有了新想法于是新建了一个dev分支并进行了一系列提交，完成后想要回到master分支，此时master分支在创建dev分支后并未产生新的commit。此时的合并就叫做fast forward。\n如下图：\n全过程的树状图为：\n合并之前：\n合并之后：\n可以看到并没有创建一个新的merge commit，而是直接将master指针移动到了dev的最新commit上。\n2. git merge \u0026amp; git revert \u0026amp; git reset 合并\u0026amp;撤销合并\u0026amp;版本回滚 # 2.1 合并分支 # 如果想要将dev分支合并到master分支上，应该先git checkout master抵达master分支，再git merge \u0026ndash;no-ff dev将dev分支合并过来 如果遇到冲突且想取消合并，git merge \u0026ndash;abort 如果遇到冲突且想解决冲突，则在编辑器中（Q: 怎么找到所有有冲突的地方？）修改后在master分支中git add -u, 再git commit -m \u0026ldquo;Merge dev into master\u0026rdquo;。 合并时遇到冲突想要取消操作，恢复index，git merge --abort\ngit show \u0026lt;commit\u0026gt;操作会显示所处的Parent的版本线索。(index)\n在合并之前要保证没有未commit的文件。如果有未commit的文件但是现在又不想提交，应该使用stash命令暂存。\n问题：git merge后如何检查是否还存在冲突没有解决？（背景：在工作中，遇到一个问题，在git merge后，发生冲突，而当冲突较多的时候，逐个检查冲突，有的时候会遗漏一些文件，导致带有冲突标记的文件上传到了 Git 服务器上，如何解决这个问题呢？）\n使用以下命令可以快速检查是否还存在有带有冲突标记的文件。 git diff --check\n2.2 撤销合并（合并回滚） # merge后没有别的操作和改动时：\ngit checkout [执行merge操作时所在的分支]\ngit reset --hard [merge前该分支所在的版本号]\n此时HEAD会在这个分支的最新commit上，此时如果需要改变HEAD的指向直接git checkout [想要切换到的分支]即可。\nmerge后还有别的操作和改动，需要回滚，这时一定不能使用reset，这会把别人的代码也干掉（因为后面的都没有了），所以只能用revert。而revert最开始被设计出来就是干这件事的。\n直接git revert \u0026lt;commit\u0026gt; 会失败，因为试图撤销两个分支的合并，git并不知道需要保留哪个分支上面的修改。所以我们需要告诉git我们保留哪个分支m或者mainline。\n-m后面的参数值可以是1或者2，对应的是parent的顺序。\n但事情并没有这么简单。因为我们在此处抛弃了之前dev合并多来的commit，下次dev再向master合并时，之前抛弃过的那部分其实并不包含在里面。把之前master那个带有反操作的commit再revert一次即可。\n$ git checkout master $ git revert rev3 $ git merge dev 3. git stash 暂存 # 背景: 如果我们不想提交完成一半或者不完善的代码，但是却不得不去修改一个紧急的bug，那个使用git stash就可以将你当前未提交到本地（和服务器）的代码推入git的栈中，这时候你的工作区间和上一次提交的内容是完全一致的。所以可以放心做你现在要干的事情，做完提交到远程服务器后，再使用git stash apply将以前完成一半的工作应用回来。\n需要说明一点，stash是本地的，不会通过git push命令上传到git server上。\n保存：\n实际应用中推荐给每个stash加一个message，用于记录版本，使用git stash save取代git stash命令。示例如下：\n$ git stash save \u0026#34;test-cmd-stash\u0026#34; 使用：\ngit stash pop(删除stash拷贝)\ngit stash apply(不删除stash拷贝)：在使用git stash apply命令时可以通过名字指定使用哪个stash，默认使用最近的stash（即stash@{0}）。\n查看：\ngit stash list\n移除：\ngit stash clear：删除所有缓存的stash\ngit stash drop: 后面可以跟着stash的名字\n$ git stash list stash@{0}: WIP on master: 049d078 added the index file stash@{1}: WIP on master: c264051 Revert \u0026#34;added file_size\u0026#34; stash@{2}: WIP on master: 21d80a5 added number to log $ git stash drop stash@{0} Dropped stash@{0} (364e91f3f268f0900bc3ee613f9f733e82aaed43) 从stash创建分支：\n如果git stash apply/pop针对的是一个你在git stash save后修改过的文件，可能会遇到冲突。\n这时候先按照解决普通的pull conflict的方式修改文件，然后执行git add [发生了冲突的文件]。一般情况下会继续git commit -m [注释]，但有时候你并不想把这些文件中的某一个作为下个commit的内容提交到远程，所以此时再执行一次git reset HEAD，就能恢复git stash pop后该有的状态了。\n需要注意的是，冲突解决之后，Git并不会删除之前的stash记录，可以使用git stash drop将没用的记录删除掉。（按理说没有冲突时，git stash pop命令会删除存储的记录，但是有冲突时并不会自动删除）。\n明天会继续学习关于git pull, git rebase, git cherry-pick等更高级的命令和它们的应用场景。\n最后 # git中文手册（全面且清晰）\nhttps://git-scm.com/book/zh/v2/\n参考 # Git如何回滚一次错误的合并\nGit取消合并(merge)、暂存修改(stash)、回退到某个版本(reset)的使用方法\ngit-stash用法小结\n执行git stash pop时的冲突解决\nHow to resolve git stash conflict without commit? \u0026ndash;Stackoverflow上的回答\n"},{"id":17,"href":"/post/2020-07-31-Android-Studio%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/","title":"Android-Studio安装记录","section":"Posts","content":" Android Studio安装记录 # 去年就搞过AS，但是因为完全零基础踩了不少坑：不知道安装SDK的前提是安装JRE/JDK；SDK和gradle下载不知道如何使用镜像站，网速很差，下载的东西根本不全，后来总是出现奇奇怪怪的问题完全不能使用。\n今年因为课程需要再次下载，现记录一下步骤备用。\n官网 版本4.0.1\n选择.exe版本下载。\n安装完成后，点击运行AS，遇到的第一个错误\n原因：电脑没有SDK而且下载的android studio又是不带SDK的；\n按照网上教程的说法，先点击Cancel，进入主页面再在SDK manager工具里面进行下载。（但是实操发现不是这么个步骤）\n点击Cancel后就一路Next进入配置步骤。但是不知道为什么又从dl.google官网上下载了一大堆东西。\n当时的配置基本情况如下：\n从显示的信息来看应该是在这一步要主动给我安装SDK，前提是你的电脑环境已经配置好了JDK。\nSetup Type: Standard SDK Folder: C:\\Users\\*****\\AppData\\Local\\Android\\Sdk JDK Location: D:\\AS\\jre (Note: Gradle may be using JAVA_HOME when invoked from command line. More info...) Total Download Size: 498 MB SDK Components to Download: Android Emulator 235 MB Android SDK Build-Tools 30.0.1 51.3 MB Android SDK Platform 30 49.9 MB Android SDK Platform-Tools 8.03 MB Android SDK Tools 149 MB Intel x86 Emulator Accelerator (HAXM installer) 2.63 MB SDK Patch Applier v4 1.74 MB 因为我的机器从官网上下载这些安装包的速度正常，所以下载很快就成功结束了。\n​\t进入导航界面，先不着急start a new project。点击Configure-\u0026gt;SDK Manager，确认自己的SDK安装完成。\n​\tSDK Platforms一栏列出了SDK的所有历史版本，其中最新版本已经安装完成。\n点击start a new project，选择默认的Empty Activity。配置信息如下：\n进入项目后，开始由AS自动下载Gradle。默认从官网下载，因为网速还可以，所以就直接默认从官网下载了。如果在国内网速不佳，参考这里。由于是首次构建项目，还要在此过程中下载Gradle，即便是网速不错依旧花了将近20分钟。\n想要运行项目还需要设置AVD（虚拟设备）。但是听说虚拟设备很吃内存，因此希望找到性能最佳的模拟器，暂时选择了AS内置的模拟器，确实很吃内存。看到网上有种方式是真机调试+apowermirror投屏到电脑上进行运行，听上去还挺不错的。\n"},{"id":18,"href":"/post/2020-06-15-Parser/","title":"Parser","section":"Posts","content":" Parser # 与表达式解析有关的题目多半要用栈或者递归来解决（我习惯用栈+迭代）。数据结构课程栈一章，中缀表达式求值算法可以供参考（核心在于两个栈，一个放操作数，一个放操作符） 这里列出了LC上关于解析的常见题目\nLC726. 原子的数量 # 题目链接\n方法1：栈+迭代 # 如果没有听说过中缀表达式求值的算法，推荐一看，对于本题的理解很有帮助。\n还是那句话，写代码的前提要知道是我们自己遇到这个问题怎么解决。\n对于给定字符串f，我们无非要做以下三件事：\n提取元素名称atom 提取紧跟着的元素个数cnt 根据括号关系计算元素出现的总次数num 对上述第三点，如果我知道两个括号之间所有的元素和他们在括号内的个数，再乘以括号后紧跟着的数字，不就能够解决了吗？\n我们设置两个容器，一个是括号栈parentheses_stack，用来匹配括号，另一个是一个元素信息列表element_info，用来记录字符串f中出现的元素的名称、当前个数、当前被几个括号包围（之所以不像中缀表达式求值那样设计两个栈，是因为在表达式求值的场景中，操作符有目数的限制，因此对放置操作数的容器只有末尾的pop和push操作，而且最后一定只有一个value做结果，因此用只栈放置操作数是可以的）\n可能有人会疑惑为什么这里要记录某元素当前被几个括号包围，实际上正是通过这个数和括号栈（只放置了(括号）的中的括号个数的大小关系，判断元素信息列表中的哪些元素的个数在本轮中需要乘以括号后的数字（这也是我认为最比较巧妙的一个点）。\n以K4(ON(SO3)2)2为例，演示过程：\n代码 # class Solution: def countOfAtoms(self, f: str) -\u0026gt; str: i = 0 n = len(f) element_info = list() # list of [element_name, number_of_element, number_of_parentheses] parentheses_stack = list() # atom = str() distribution = dict() while i \u0026lt; n: # 如果遇到的是字母 # 如果遇到的是大写字母 atom = str() if f[i].isupper(): atom = f[i] i += 1 # 跟着小写字母 while i \u0026lt; n and f[i].islower(): atom += f[i] i += 1 cnt = str() # 如果后面有数 if i \u0026lt; n and f[i].isdigit(): # 遍历所有的数 while i \u0026lt; n and f[i].isdigit(): cnt += f[i] i += 1 element_info.append([atom, int(cnt), len(parentheses_stack)]) # 如果后面没有数 else: # 如果前面的if都执行过（即得到了某一个atom，而不是一开始就从(开头） # print(\u0026#34;i, atom:\u0026#34;, i, atom) if len(atom) and len(cnt) == 0: element_info.append([atom, 1, len(parentheses_stack)]) if i \u0026lt; n and f[i] == \u0026#39;(\u0026#39;: parentheses_stack.append(\u0026#39;(\u0026#39;) i += 1 elif i \u0026lt; n and f[i] == \u0026#39;)\u0026#39;: i += 1 cnt = str() if i \u0026lt; n and f[i].isdigit(): # 遍历所有的数 while i \u0026lt; n and f[i].isdigit(): cnt += f[i] i += 1 cnt = int(cnt) else: cnt = 1 for k in range(len(element_info)-1,-1,-1): if element_info[k][2] == len(parentheses_stack): element_info[k][1] *= cnt element_info[k][2] -= 1 else: break parentheses_stack.pop() for ele in element_info: if ele[0] in distribution: distribution[ele[0]] += ele[1] else: distribution[ele[0]] = ele[1] lst = sorted(distribution.items(), key=lambda obj: obj[0]) ans = str() for name, number in lst: if number == 1: ans += name else: ans += name + str(number) return ans 方法2：递归（官方题解） # "},{"id":19,"href":"/post/2020-06-11-%E5%8F%8C%E6%8C%87%E9%92%88/","title":"双指针","section":"Posts","content":" 双指针 # 有以下几种情况：\n首尾开始，向中间移动，直到两者相遇（这种情况数组通常是有序的） 都从头开始，同时向后移动，直到其中一个到达末尾 快慢指针算法（比如找链表的中点，倒数第N个点等等） 几个编程时要注意的问题：\n移动指针时千万注意不要越界！不要越界！不要越界！在while条件部分的前面加上判断！ LC15. 三数之和 # 题目链接\n这题要求是三数之和为0，且不能重复。\n三数之和为0比较好办，先对数组进行排序，然后对下标i, j, k依次固定i，对数组后面的部分执行2sum算法即可。\n不能重复怎么办？那就先看看什么情况下会发生重复。\n清楚了这一点后本题就变得很简单了！\n时间复杂度$O(n^2)$，空间复杂度$O(n)$\nclass Solution: def threeSum(self, nums: List[int]) -\u0026gt; List[List[int]]: nums.sort() # print(nums) N = len(nums) if N \u0026lt;= 2: return list(list()) i = 0 lst = list() while i \u0026lt; N - 2: j, k = i + 1, N - 1 # print(i) while j \u0026lt; k: if nums[j] + nums[k] \u0026gt; -nums[i]: k -= 1 elif nums[j] + nums[k] \u0026lt; -nums[i]: j += 1 else: # print(j, k) lst.append([nums[i], nums[j], nums[k]]) # 本处0 \u0026lt; j \u0026lt; k \u0026lt;= N - 1, j,k分别移动一个之后都不会越界 # 用这种语法代替do while循环 j += 1 k -= 1 # 尤其要注意越过所有相等的数字时务必要避免越界！ while j \u0026lt; N and nums[j] == nums[j - 1]:\tj += 1 while k \u0026gt;= 0 and nums[k] == nums[k + 1]: k -= 1 # update i i += 1 while i \u0026lt; N and nums[i] == nums[i - 1]: i += 1 return lst LC18. 四数之和 # 题目链接\n实际上是三数之和的进阶版。三数之和固定（所谓固定就是遍历）一个i，而j和k使用双指针方法包夹求解。四数之和则依次固定i,j，而a和b使用双指针方法包夹求解。\n另外发现一件事情：双指针方法纯粹是降低复杂度的小trick，有点像是“剪枝”，某些不可能的组合都不给你遍历的机会！使用了双指针能够少一次$O(n)$的遍历，这也就是为什么，两数之和暴力法$O(n^2)$，双指针法$O(n)$；三数之和暴力法$O(n^3)$而双指针法$O(n^2)$；四数之和暴力法$O(n^4)$而双指针法$O(n^3)$。幂次能减一。\n整个算法流程和LC15非常类似，连避免重复的技巧也是一样的。\nclass Solution: def fourSum(self, nums: List[int], target: int) -\u0026gt; List[List[int]]: nums.sort() n = len(nums) lst = list() if n \u0026lt; 4: return lst i = 0 while i \u0026lt; n: j = i + 1 while j \u0026lt; n: p = nums[i] + nums[j] a = j + 1 b = n - 1 while a \u0026lt; b: if nums[a] + nums[b] + p \u0026lt; target: a+=1 elif nums[a] + nums[b] + p \u0026gt; target: b-=1 else: lst.append([nums[i],nums[j],nums[a],nums[b]]) a+=1 b-=1 while a \u0026lt; n and nums[a] == nums[a-1]: a+=1 while b \u0026gt;= 0 and nums[b] == nums[b+1]: b-=1 j += 1 while j \u0026lt; n and nums[j] == nums[j-1]: j+=1 i+=1 while i \u0026lt; n and nums[i] == nums[i-1]: i+=1 return lst "},{"id":20,"href":"/post/2020-06-09-%E5%8D%95%E8%B0%83%E6%A0%88/","title":"单调栈","section":"Posts","content":" 单调栈 # 单调栈，顾名思义，是栈中的元素满足一定的单调性。对于从栈底到栈顶单调减少的单调栈，在向栈顶push元素的时候，如果栈顶元素比该元素小，则直接push进去；如果栈顶元素比该元素大，则将栈顶元素pop出来，再比较新的栈顶元素与该元素的大小。实际上我们在使用单调栈的时候，很少直接存储数值，而是存储数组下标，C++代码如下：\nstack\u0026lt;int\u0026gt; monotonestk; // insert the ith number of vector \u0026#39;nums\u0026#39; while(!monotonestk.empty() \u0026amp;\u0026amp; nums[monotonestk.top()] \u0026lt; nums[i])\t// 单调递减的栈 monotonestk.pop(); monotonestk.push(i); 实际上在数据结构课堂上老师讲过用这个解决直方图最大矩形的问题，其中一个算法细节还在期中考试考过，但是当时理解并不深刻。\n基础应用 # 从知乎专栏上看到这样一个问题，据说是该专栏作者在谷歌的模拟面试题（笔者想起了自己的Google面试经历，说难不难说简单也不简单，还是很考察算法功力的，当然自己有待提升的地方还有很多）：给定一个数组，请返回在这个数组中，每一个数往右边走几步可以到达比它大的第一个数，以数组的形式返回。如果右边没有比它大的数，则认为走-1步。\n暴力的做法时间上是$O(n^2)$的，空间上除了保存输入数据以外的额外开销是$O(1)$。每次以第$i$个元素为起点，向右边找第一个大于它的数字，返回下标差。\n但很明显我们在这个过程中做了重复计算。以第0个元素为起点时，其实我们遍历到了之后所有的元素（后面其实在不断做重复的遍历），怎么样把一次遍历得到的信息保存下来呢？“存”当然是用数据结构，但是怎么表达元素之间那种“相邻”的大小关系呢？（就比如说这题的，找到下一个比nums[i]大的数在哪里？）\n单调栈可以为我们所用。我们需要找到每一个数右边第一个比它大的数字，联系一下单调栈的入栈方式：如果比栈顶小，直接入栈（这时入栈的nums[i]一定不是栈顶元素右边第一个比它大的数）；如果比栈顶大，则先将栈顶的元素pop出来，关键点就在这里，所有元素在出栈的那一刻不就找到了自己右边第一个比自己大的数了吗？\n一个细节问题：是不是所有的元素都有出栈的时刻？显然不是。我记得上课时邓公提过一个问题，问我们算法执行完毕后单调栈中的内容是什么含义。当时想不明白，现在明白了：实际上就是在数组中，右边没有比它大的数的那些数的下标（很有点绕口啊）。因此对于无法从栈中弹出的元素，它们的答案就是-1。由于能弹出就可以更新而不能弹出则不能更新，在初始化时将所有元素的答案初始化为-1即可。\n每一个位置只会入栈一次（在枚举到它时），并且最多出栈一次，因此时间复杂度为$O(n)$，另外开了一个栈，空间复杂度$O(n)$。\n代码如下：\nvector\u0026lt;int\u0026gt; getBiggerRight(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;int\u0026gt; res(nums.size(), -1); stack\u0026lt;int\u0026gt; stk; for(int i = 0; i \u0026lt; nums.size(); i++) { while(!stk.empty() \u0026amp;\u0026amp; nums[stk.top()] \u0026lt; nums[i]) {\t// 单调递减的栈 res[stk.top()] = i - stk.top(); stk.pop(); } stk.push(i); } return res; } 进阶1：LC84. 直方图最大矩形 # 先来说说一个trivial的思路（不是官方解答）。既然上面的方法可以求出右侧第一个比自己大的数，那么同样可以求出左、右侧第一个比自己小的数。\n首先明确两点。既然答案是最大矩形，那么这个矩形的高度一定是直方图中某一个小条形的高度；矩形的宽度一定是向两边延伸的最大值（即再往左/右一定就遇到比自己小的高度了，不能再以当前高度为矩形的高了）。明确了这两点以后可以知道，只需要做三次线性扫描，答案就可以出来：\n从左往右，找右侧第一个比自己小的数的坐标 从右往左，找左侧第一个比自己小的数的坐标 无特殊的扫描方向。就从左往右吧，依次计算以各个条形高度为矩形的高度时，矩形的面积。在此过程中取最大值，即为所求。 代码如下：\nclass Solution { public: int largestRectangleArea(vector\u0026lt;int\u0026gt;\u0026amp; heights) { int n = heights.size(); stack\u0026lt;int\u0026gt; stk; // 下面这样初始化的理由是：可以认为-1和n处的高度为0 vector\u0026lt;int\u0026gt; left(n, -1); // 如果左侧没有比自己小的，则认为比自己小的都在-1处 vector\u0026lt;int\u0026gt; right(n, n); // 如果右侧没有比自己小的，则认为比自己小的都在n处 for(int i = 0; i \u0026lt; n; i++) { while(!stk.empty() \u0026amp;\u0026amp; heights[stk.top()] \u0026gt; heights[i]) { right[stk.top()] = i; stk.pop(); } stk.push(i); } stk = {}; for(int i = n - 1; i \u0026gt;= 0; i--) { while(!stk.empty() \u0026amp;\u0026amp; heights[stk.top()] \u0026gt; heights[i]) { left[stk.top()] = i; stk.pop(); } stk.push(i); } int ans = 0; for(int i = 0; i \u0026lt; n; i++) { ans = max(ans, heights[i] * (right[i] - left[i] - 1)); } return ans; } }; 官方解答：\n单调栈+常数优化\n再思考一个问题：能不能通过一遍扫描，求出左边界和右边界？\n拿单调增的栈举例，从左往右扫描，则元素入栈时，可求出左边第一个比自己小于等于的数；元素出栈时，可求出右边第一个比自己小的数。\n但我们需要求的是左边比自己小的数！会不会影响结果呢？\n答案是不会。因为如果有**在单调栈中连续的（这个限定非常重要，因为并不是只要在直方图中高度相同就可以在单调栈中处于连续位置，前提是在直方图里，它们之间没有更小高度的条形）**相同高度的条形，则最左边的条形可以求出正确的左边界，而这些条形的右边界都是对的。所以即便中间那些高度的条形求出的结果不正确（比实际值小），也不会影响最后的答案！\n优化后的代码：\nclass Solution { public: int largestRectangleArea(vector\u0026lt;int\u0026gt;\u0026amp; heights) { int n = heights.size(); stack\u0026lt;int\u0026gt; stk; // 下面这样初始化的理由是：可以认为-1和n处的高度为0 (所谓的哨兵技巧) vector\u0026lt;int\u0026gt; left(n, -1); // 如果左侧没有比自己小的，则认为比自己小的都在-1处 vector\u0026lt;int\u0026gt; right(n, n); // 如果右侧没有比自己小的，则认为比自己小的都在n处 for(int i = 0; i \u0026lt; n; i++) { while(!stk.empty() \u0026amp;\u0026amp; heights[stk.top()] \u0026gt; heights[i]) { right[stk.top()] = i; stk.pop(); } if(!stk.empty()) left[i] = stk.top(); stk.push(i); } int ans = 0; for(int i = 0; i \u0026lt; n; i++) { ans = max(ans, heights[i] * (right[i] - left[i] - 1)); } return ans; } }; 进阶2： LC85. 最大矩形 # 这道题确实有难度，我自己只能想到暴力解法。\n方法1：转化为上面一题 # 不得不说好难想到！不过官网题解倒是能让我们理解这个做法是怎么一步步得到的。\n解法1：枚举所有的(x1, y1)和(x2 y2)，统计以之为对角线的矩形的面积。 解法2：枚举所有的(x, y)，统计以(0, 0), (x, y)为对角线的最大矩形面积。这时候出现一个概念：每一行中每一个方块连续的“1”的数量。有了这个概念后，我们实际上可以得到一系列旋转了90°的直方图。 从解法2，联系上一题可以得到时间复杂度$O(MN)$，空间复杂度$O(MN)$（优化后可以达到$O(M)$）的算法。\n求最大矩形的面积，我们不妨逐行来看，求出每一行上的heights[]即可。\n代码如下：\nclass Solution { int leetcode84(vector\u0026lt;int\u0026gt;\u0026amp; heights) { int n = heights.size(); stack\u0026lt;int\u0026gt; stk; // 下面这样初始化的理由是：可以认为-1和n处的高度为0 (所谓的哨兵技巧) vector\u0026lt;int\u0026gt; left(n, -1); // 如果左侧没有比自己小的，则认为比自己小的都在-1处 vector\u0026lt;int\u0026gt; right(n, n); // 如果右侧没有比自己小的，则认为比自己小的都在n处 for(int i = 0; i \u0026lt; n; i++) { while(!stk.empty() \u0026amp;\u0026amp; heights[stk.top()] \u0026gt; heights[i]) { right[stk.top()] = i; stk.pop(); } if(!stk.empty()) left[i] = stk.top(); stk.push(i); } int ans = 0; for(int i = 0; i \u0026lt; n; i++) { ans = max(ans, heights[i] * (right[i] - left[i] - 1)); } return ans; } public: int maximalRectangle(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); if(m == 0) return 0; int n = matrix[0].size(); if(n == 0) return 0; // 其实可以空间优化到O(n) vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; height(m, vector\u0026lt;int\u0026gt;(n, 0)); for(int i = 0; i \u0026lt; n; i++) { height[0][i] = matrix[0][i] == \u0026#39;1\u0026#39; ? 1: 0; } for(int i = 1; i \u0026lt; m; i++) { for(int j = 0; j \u0026lt; n; j++) { height[i][j] = matrix[i][j] == \u0026#39;1\u0026#39; ? height[i-1][j] + 1: 0; } } int ans = 0; for(int i = 0; i \u0026lt; m; i++) { ans = max(ans, leetcode84(height[i])); } return ans; } }; 空间优化部分：\n// 其实可以空间优化到O(n) vector\u0026lt;int\u0026gt; preheight(n, 0); vector\u0026lt;int\u0026gt; height(n, 0); for(int i = 0; i \u0026lt; n; i++) { preheight[i] = matrix[0][i] == \u0026#39;1\u0026#39; ? 1: 0; } int ans = 0; ans = max(ans, leetcode84(preheight)); for(int i = 1; i \u0026lt; m; i++) { for(int j = 0; j \u0026lt; n; j++) { height[j] = matrix[i][j] == \u0026#39;1\u0026#39; ? preheight[j] + 1: 0; } preheight = height; ans = max(ans, leetcode84(preheight)); } 方法2：动态规划 # 动态规划实际上就是找每层之间的联系。\n我们可以认为本题是从第0层到第m-1层逐层扩展。方法1中逐层化解为84题，每层都是根据heights数组重新求一遍left和right。实际上我们可以延续动态规划的思想，类似height[]的逐层更新，从上一层的left[]和right[]得到下一层的left[]和right[]。\n我们可以画一张图表示第i-1层和第i层之间的关系：\n从图中可以看出，第i层的left或者right产生变化当且仅当这一层出现过0，具体转移方程见图。\nclass Solution { public: int maximalRectangle(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); if(m == 0) return 0; int n = matrix[0].size(); if(n == 0) return 0; vector\u0026lt;int\u0026gt; preheight(n, 0); vector\u0026lt;int\u0026gt; height(n, 0); vector\u0026lt;int\u0026gt; left(n, 0); vector\u0026lt;int\u0026gt; preleft(n, -1); vector\u0026lt;int\u0026gt; right(n, 0); vector\u0026lt;int\u0026gt; preright(n, n); int ans = 0; int curleft, curright; for(int i = 0; i \u0026lt; m; i++) { // update height for(int j = 0; j \u0026lt; n; j++) { height[j] = matrix[i][j] == \u0026#39;1\u0026#39; ? preheight[j] + 1 : 0; } // update left curleft = -1; for(int j = 0; j \u0026lt; n; j++) { if(matrix[i][j] == \u0026#39;1\u0026#39;) left[j] = max(preleft[j], curleft); else if(matrix[i][j] == \u0026#39;0\u0026#39;) { curleft = j; left[j] = -1; } } curright = n; for(int j = n - 1; j \u0026gt;= 0; j--) { if(matrix[i][j] == \u0026#39;1\u0026#39;) right[j] = min(preright[j], curright); else if(matrix[i][j] == \u0026#39;0\u0026#39;) { curright = j; right[j] = n; } } for(int j = 0; j \u0026lt; n; j++) { ans = max(ans, height[j] * (right[j] - left[j] - 1)); } preheight = height; preleft = left; preright = right; } return ans; } }; 方法3：位运算加速 # 看到评论区有大神用二进制位表示状态\n是用python解决的，因为用C语言表示会溢出（精度不足）\n今天实在太累，明天看懂了再继续写吧\n"}]